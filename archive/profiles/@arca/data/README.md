# ğŸ“ Carpeta `data/`

Esta carpeta contiene **toda la estructura de datos** utilizada por el sistema principal (`main.py`). Se organiza en etapas de procesamiento progresivas, respetando buenas prÃ¡cticas de trazabilidad, escalabilidad y reutilizaciÃ³n en flujos de machine learning y anÃ¡lisis automatizado.

---

## ğŸ“ Estructura general

```bash
/data/
â”œâ”€â”€ raw/         # Datos crudos sin procesar, tal como fueron obtenidos
â”œâ”€â”€ staging/     # Zona temporal para limpieza, validaciÃ³n y preprocesamiento
â”œâ”€â”€ processed/   # Datos estructurados con metadatos extraÃ­dos y listos para anÃ¡lisis
â”œâ”€â”€ features/    # Representaciones vectoriales, embeddings u otros features derivados
â”œâ”€â”€ models/      # (Opcional) Modelos entrenados sobre los datos procesados
â””â”€â”€ logs/        # Logs del procesamiento, errores, auditorÃ­as y trazabilidad
```

---

## ğŸ§± DescripciÃ³n por carpeta

### `/raw/`
- AquÃ­ se almacenan los archivos originales (Markdown, YAML, scripts, etc.).
- **No deben modificarse** ni sobrescribirse.
- Se acepta desorden, duplicaciÃ³n y formatos variados.
- Puede tener subcarpetas por tipo (`/raw/md/`, `/raw/yaml/`, etc.).

### `/staging/`
- Espacio de trabajo intermedio.
- AquÃ­ se calcula el **hash** de los archivos, se detectan duplicados y se extraen estructuras bÃ¡sicas.
- Se valida el formato de los datos antes de pasarlos a la siguiente etapa.

### `/processed/`
- Archivos con metadatos extraÃ­dos, convertidos a formatos homogÃ©neos (`.json`, `.csv`, etc.).
- Organizados e indexados por tema, autor, fecha o proyecto.
- Se considera la base consolidada para el anÃ¡lisis.

### `/features/`
- Representaciones numÃ©ricas Ãºtiles para aprendizaje automÃ¡tico (ej. vectores de texto, embeddings).
- Base para clustering, clasificaciÃ³n, bÃºsqueda semÃ¡ntica, etc.

### `/models/` *(opcional)*
- Almacenamiento de modelos entrenados con estos datos.
- Se recomienda guardar metadata del modelo junto con el archivo (`.json`, `.pkl`, etc.).

### `/logs/`
- Registros del procesamiento: errores, acciones, timestamps, hash detectados.
- Ãštil para debugging y auditorÃ­a.

---

## ğŸ“Œ Consideraciones

- Toda la configuraciÃ³n estÃ¡ centralizada en `config.yaml` en la raÃ­z del proyecto.
- El punto de entrada del sistema es `main.py`, que debe respetar esta estructura.
- Se recomienda no eliminar ni modificar manualmente los archivos en `/staging/` o `/processed/`.

---

## âœ… Convenciones internas

- Los archivos procesados deben incluir:
  - Hash Ãºnico del contenido (`blake3` recomendado).
  - Timestamp de procesamiento.
  - Fuente de origen (`raw_path`, etc.).
  - Etiquetas extraÃ­das, si aplica.

- El sistema debe permitir re-procesar el `raw` sin duplicar datos ya presentes en `processed`.

---

## ğŸ“š PrÃ³ximos pasos sugeridos

- Agregar esquemas (`schemas/`) para validar tipos de datos en `staging`.
- Incorporar versionado semÃ¡ntico de datasets.
- Integrar un indexador semÃ¡ntico o motor de bÃºsqueda (ej: con embeddings).
- Permitir retroalimentaciÃ³n al sistema para mejorar clasificaciÃ³n automatizada.

---

Este `README.md` debe mantenerse actualizado si se modifica la estructura de `data/`.
