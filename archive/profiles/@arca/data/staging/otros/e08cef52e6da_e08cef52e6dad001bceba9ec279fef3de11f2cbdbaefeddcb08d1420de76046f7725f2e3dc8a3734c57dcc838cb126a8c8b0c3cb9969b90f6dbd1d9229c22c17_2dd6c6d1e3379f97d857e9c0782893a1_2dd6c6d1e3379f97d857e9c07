# Servidor LLM local
# TODO: Cargar modelo GGUF con llama.cpp
