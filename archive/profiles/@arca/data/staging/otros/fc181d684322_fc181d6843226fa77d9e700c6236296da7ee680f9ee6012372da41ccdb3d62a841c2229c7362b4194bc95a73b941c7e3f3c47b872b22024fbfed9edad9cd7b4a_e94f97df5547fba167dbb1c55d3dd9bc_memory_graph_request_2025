---
module: prompts/memory_graph_request
type: core
status: in_progress
created: '2025-05-26'
linked_to:
- metodologia_doc_ia_v2.md

---
# ğŸ§  Solicitud de ImplementaciÃ³n â€“ `memory_graph.py` â€“ Sprint 2.6 â€“ ALMA_RESIST

## ğŸ¯ Objetivo

Implementar el mÃ³dulo `memory_graph.py`, responsable de construir un grafo semÃ¡ntico de interacciones basado en los prompts y respuestas registradas por el servidor ALMA_RESIST. Este mÃ³dulo servirÃ¡ como base para el razonamiento reflexivo y bÃºsqueda de memoria contextual.

---

## ğŸ“˜ Requisitos

### Clase: `MemoryGraph`

- MÃ©todos esperados:
  - `add_node(concept: str) -> str`  
    Agrega un nodo Ãºnico al grafo semÃ¡ntico.
  - `create_edge(from_concept: str, to_concept: str, weight: float = 1.0) -> None`  
    Crea una relaciÃ³n ponderada entre dos conceptos.
  - `get_related(concept: str, top_k: int = 5) -> list[str]`  
    Recupera los conceptos mÃ¡s relacionados a partir de pesos acumulados.
  - `export_graph(file_path: str) -> None`  
    Exporta el grafo a JSON o GraphML para visualizaciÃ³n futura.

### Condiciones:
- Guardar estructura internamente como diccionario `{ nodo: { nodo_vecino: peso } }`
- Prevenir duplicados en nodos
- Incrementar peso si la relaciÃ³n ya existe
- Guardar el grafo en archivo local `memory_graph.json`
- Preparado para extender a FAISS o embedding vectorial en el futuro

---

## ğŸ§ª Ejemplo de uso

```python
from integration.memory_graph import MemoryGraph

mg = MemoryGraph()
mg.add_node("inteligencia")
mg.add_node("adaptaciÃ³n")
mg.create_edge("inteligencia", "adaptaciÃ³n", weight=0.9)
mg.get_related("inteligencia")
```

---

## ğŸ“ Contexto

- Sprint: 2.6 â€“ LLM Server
- Integra datos desde: `context_tracker`, `TransportLayer`
- Fundamento del mÃ³dulo de reflexiÃ³n semÃ¡ntica de ALMA
