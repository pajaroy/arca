# ğŸ§  GuÃ­a de Uso â€“ Servidor ALMA_RESIST

## âœ… Paso 1: Instalar dependencias necesarias

```bash
# Activa tu entorno virtual si no lo estÃ¡
source .venv/bin/activate

# Instala las dependencias principales
pip install fastapi uvicorn llama-cpp-python python-multipart cryptography jsonschema
```


## ğŸ§ª Endpoints principales

### 1. Generar respuestas (POST /responder)

```bash
curl -X POST "http://localhost:8000/responder" \
-H "Content-Type: application/json" \
-d '{"prompt": "Â¿CuÃ¡l es el sentido de la vida?"}'
```

Respuesta esperada:
```json
{
  "respuesta": "El sentido de la vida es...",
  "metadata": {
    "modelo": "mistral-7b-q4.gguf",
    "longitud_prompt": 28,
    "timestamp": "2023-10-15T12:34:56.789Z"
  }
}
```


### 3. Obtener historial de contexto (GET /context/history)

```bash
curl "http://localhost:8000/context/history?limit=3"
```


### 5. Cifrar logs (POST /logs/encrypt)

```bash
curl -X POST http://localhost:8000/logs/encrypt
```


## ğŸ“ Estructura recomendada del proyecto

```
ALMA_RESIST/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ llm_server/
â”‚       â”œâ”€â”€ models/              # Modelos GGUF
â”‚       â”œâ”€â”€ transport_data/      # Datos de transporte
â”‚       â”œâ”€â”€ docs/contracts/      # Esquemas JSON
â”‚       â””â”€â”€ logs/                # Logs cifrados
```


## ğŸ›  Troubleshooting

### Verificar dependencias:

```bash
pip list | grep -E 'fastapi|uvicorn|llama-cpp-python'
```

### Logs al iniciar:

```text
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using WatchFiles
INFO:     Started server process [12347]
INFO:     Waiting for application startup.
INFO:     alma_server: Modelo models/mistral-7b-q4.gguf cargado exitosamente
INFO:     Application startup complete.
```

