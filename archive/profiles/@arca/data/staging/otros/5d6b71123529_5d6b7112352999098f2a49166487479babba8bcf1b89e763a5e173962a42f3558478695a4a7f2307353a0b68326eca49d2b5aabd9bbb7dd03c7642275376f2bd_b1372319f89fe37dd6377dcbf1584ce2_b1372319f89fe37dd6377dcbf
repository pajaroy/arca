

2025-05-29
🔁 Se archivó metodología antigua de estructuras autónomas como versión v0.1.
📘 Nueva versión mejorada registrada en: docs/metodologia_estructura_autonoma_v2.md

## 🗓️ 2025-06-03 – Incorporación de nueva metodología CLI-IA

### ✅ Cambios realizados:
- Se creó el archivo metodológico: **metodología para entornos CLI integrados con IA**.
- Se integró a la carpeta `/docs/metodologias/` con nombre fechado para trazabilidad.
- Se definió que todos los archivos de metodología deben tener formato fechado.
- Se habilita uso de enlaces relativos para trazabilidad desde changelog y otros módulos.

`](./metodologias/2025-06-03_metodologia_estructura_cli_ia_v1.md)
### 🔗 Archivo relacionado:
[[docs/metodologias/2025-06-03_metodologia_estructura_cli_ia_v1|2025-06-03_metodologia_estructura_cli_ia_v1]]

### 🏷️ Tags:
#metodologia #cli #ia #estructura #trazabilidad #alma_resist


🔗 Archivos clave:  
- `[[Kael]]`  
- `[[criterios_ubicacion_vivo.md]]`  
- `[[2025-06-03_apendice_nombres_modulos_ejecutables.md]]`  
- `[[tree_alma_resist.md]]` – `[[tree_control_central.md]]` – `[[tree_core.md]]`


module: introduccion/context
type: core
status: in_progress
created: '2025-05-23'
linked_to:
- metodologia_doc_ia_v2.md


## 🧾 Contexto Histórico

El presente documento refleja la evolución progresiva del sistema ALMA_RESIST.  
Se conserva el historial técnico para trazabilidad de decisiones, cierres de sprint y evolución modular.


## 🗂 Estructura Base

```
ALMA_RESIST/
├── core/                  → Módulos funcionales actuales
├── tests/                 → Test unitarios por módulo
├── prompts/               → Prompts técnicos asociados
├── docs/                  → Documentación técnica, histórica y estratégica
├── logs/                  → Registros estructurados (pueden estar cifrados)
└── scripts/               → Scripts auxiliares (arranque, backups, automatizaciones)
```


## 🧱 Módulos Técnicos Actuales

| Módulo               | Ubicación             | Estado  |
|----------------------|------------------------|---------|
| Logging estructurado | `core/log_writer.py`   | ✅ |
| Cifrado de logs      | `core/log_crypto.py`   | ✅ |
| ALMA_LOADER base     | `core/loader.py`       | 🧪 (prototipo) |


## 🧭 Próximos Pasos

👉 Crear checklist para Sprint Técnico 0.0.0.3  
👉 Definir objetivo técnico: CLI inteligente, memoria modular, IA mínima funcional  
👉 Iniciar integración de reflexión automatizada y feedback semántico de documentos

## 📎 Apéndice – Estado operativo validado (2025-05-23)

El sistema ALMA_RESIST implementa un pipeline interno de validación documental completamente funcional y validado, alineado con la metodología modular declarada.

### 🧠 Capacidades integradas

- Validación sintáctica y semántica de todos los archivos `.md` mediante `validate_docs.py`
- Corrección automática de metadatos YAML (`fix_metadata.py`)
- Normalización de rutas modulares (`force_snake_case_modules.py`)
- Ejecución centralizada vía script bash (`validar_documentacion.sh`)
- Backup automático de los cambios en carpetas versionadas
- Registro sistemático en bitácoras, changelogs y decisiones arquitectónicas

### 📁 Documentación asociada

- `docs/utilidades/`
- `docs/decisiones_arquitectonicas.md`
- `docs/changelog.md`
- `docs/resgistros/bitacoras/bitacora_2025-05-23.md`
- `scripts/`

Este conjunto funcional sienta la base para una futura integración CI/CD y garantiza trazabilidad completa sobre la estructura viva del sistema.


## 🔄 Apéndice Sprint 2.5

Durante este sprint se consolidó la estructura modular como arquitectura final del sistema. Se validaron nombres, carpetas, scripts, y puntos de entrada. El contexto general ahora puede ser interpretado tanto por humanos como por asistentes IA, facilitando búsquedas, automatizaciones y trazabilidad.

El contenido anterior de este archivo queda como referencia del proceso previo al rediseño.


title: "Bitácora de Instalación ALMA_RESIST"
date: 2025-06-01
tags: [#instalacion, #alma_resist, #configuracion_inicial, #bitacora, #alma_core, #alma_cli, #obsidian, #input_leap, #tmux, #rsync, #parrot_os]
module: alma_resist
type: bitacora
status: validado
linked_to: [control_central, alma_cli/auditor_textos, metodologias/estructura_autonoma]

## ✅ 1. Instalación de paquetes base

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y git curl tmux vim htop net-tools openssh-server unzip rsync sqlite3 python3 python3-pip tree
```


## 🔗 3. Configuración de red y sincronización SSH

- **Nodos**:
  - ALMA_CORE → `192.168.1.33`
  - ALMA_RESIST → `192.168.1.36`

Verificar conectividad:

```bash
ssh bird@192.168.1.36
ssh bird@192.168.1.33
```

Generar y copiar claves SSH:

```bash
ssh-keygen -t ed25519 -C "bird@alma-resist"
ssh-copy-id bird@192.168.1.33
```


## 🧱 5. Instalación y uso básico de Tmux

```bash
sudo apt install tmux -y
tmux new -s alma_core
tmux new -s alma_resist
```

Atajos:
- Ctrl+b → % (dividir horizontal)
- Ctrl+b → " (dividir vertical)
- Ctrl+b → c (nueva ventana)
- Ctrl+b → d (detach)


## 🖼️ Fix íconos faltantes en Obsidian

```bash
sudo apt install -y fonts-noto fonts-noto-color-emoji fonts-material-design-icons-iconfont fonts-roboto fonts-font-awesome
fc-cache -fv
```


# 🧩 Proyección IA-Friendly

Este archivo incluye:

- `tags` normalizados
- `linked_to` a módulos clave
- Bitácora en formato markdown y versionable
- Estructura compatible con CLI y agentes LLM futuros

Ideal para ser indexado por el módulo `auditor_textos` y alimentar motores de búsqueda interna semántica en el ecosistema ALMA.


# [FIN DEL DOCUMENTO]




module: metodologias/archivadas/metodologia_adr_v1
type: core
status: in_progress
created: '2025-05-21'
linked_to:
- metodologia_doc_ia_v2.md


## ✅ ¿Qué es un ADR?

Un **Architecture Decision Record (ADR)** es un documento que responde:  
> “¿Por qué tomamos esta decisión técnica en este punto del tiempo?”

Su objetivo es dejar constancia de **decisiones estructurales, tecnológicas o estratégicas** que pueden afectar la evolución futura del sistema.


## 📁 Ubicación oficial

Todos los ADR deben guardarse en:  
```
docs/adr/
```

Nombrados de forma incremental y descriptiva:

```
docs/adr/001-estructura-modular.md
docs/adr/002-versionado-semver.md
docs/adr/003-ia-local-mistral.md
```


## 📘 Ejemplo real

```markdown
# ADR 002 – Adopción de versionado SemVer

📅 Fecha: 2025-05-18  
🎯 Estado: Adoptado

## Decisión
Utilizar `MAJOR.MINOR.PATCH` como convención de versionado global.

## Contexto
Se necesitaba un estándar para versionar snapshots y scripts sin ambigüedad.

## Alternativas consideradas
- Fechas (`2025-05-18`)
- Commit hashes
- Versionado manual ad-hoc

## Justificación
SemVer es ampliamente utilizado, fácil de entender y permite automatización futura.

## Impacto
Afecta a changelog.md, backups, carpetas `/versiones/`, y documentación general.

## Relacionado con
- metodologia_versionado_backups_v1.md
- Sprint_2.2
```

## Archivo: metodologia_doc_ia_v1.md
Contenido:
# 📘 Metodología de Documentación para Humanos + IA – ALMA_RESIST (v1)

📅 Versión: 1.0  
📁 Archivo: metodologia_doc_ia_v1.md  
🎯 Objetivo: Establecer un estándar de documentación que sea simultáneamente legible para humanos, y navegable, indexable y procesable por sistemas de IA como Alma.


## 🧠 Fundamento

La IA funciona mejor cuando la documentación:

- Tiene **estructura explícita**
- Usa **tags consistentes**
- Declara **relaciones entre módulos**
- Se puede leer como una base de datos viva

Por eso se define el uso obligatorio del bloque `frontmatter` YAML.

module: "core/cli"
type: "core"          # core | external | tool | integration | draft
domain: "infraestructura"   # general | cultivo | historia | ia | trading
tags: ["CLI", "modularidad", "entrada"]
status: "stable"      # in_progress | stable | deprecated
linked_to: ["memoria", "resumen"]
created: "2025-05-21"
version: "0.2"

## 🏷️ Campos requeridos

| Campo       | Descripción técnica                                                        |
|-------------|-----------------------------------------------------------------------------|
| `module`    | Identificador único del módulo o documento                                  |
| `type`      | Tipo de documento: núcleo, externo, herramienta, integración, etc.          |
| `domain`    | Dominio funcional principal (ej: cultivo, historia, IA, trading)            |
| `tags`      | Lista de palabras clave normalizadas                                        |
| `linked_to` | Otros módulos relacionados                                                  |
| `status`    | Estado del documento                                                        |
| `version`   | Versión local del documento o módulo                                        |
| `created`   | Fecha de creación                                                           |


## 📘 Ejemplo completo

```markdown

# Loader – Núcleo de Carga de Modelo LLM

Este módulo se encarga de inicializar, cargar y coordinar el modelo IA local utilizado por Alma...
```


## 🔄 Relación con otras metodologías

- Requiere implementación dentro de: `estructura_modular_v2`
- Afecta directamente a: `sprints_v2`, `auditoría_adr`, `interacción_ia`
- Será utilizada en: `alma-cli`, `alma-loader`, `grafos_ia`

## Archivo: metodologia_estructura_autonoma_v1.md
Contenido:
# Metodología de Trabajo en Carpetas Autónomas

Esta metodología define la estructura mínima y escalable para trabajar de manera autónoma dentro de una carpeta, útil para proyectos personales, módulos temáticos o pruebas aisladas dentro del entorno ALMA_RESIST.

## 📁 Estructura base sugerida

```bash
nombre_modulo/
├── docs/                    # Documentación del módulo (readme, changelog, bitácoras)
│   ├── readme.md            # Descripción del módulo
│   ├── version.md           # Versión actual del módulo
│   └── bitacoras/           # Notas de trabajo fechadas
├── datasets/                # Datos crudos o procesados (CSV, JSON, etc.)
├── scripts/                 # Scripts Python o Bash de procesamiento o validación
├── notebooks/               # Notebooks de análisis o pruebas exploratorias
├── downloads/               # Archivos externos temporales (nunca en git)
├── tests/                   # Pruebas unitarias o de integración
├── logs/                    # Logs de ejecución, errores o auditorías
└── config/                  # Configuraciones, variables de entorno, APIs
```

## ✅ Buenas prácticas

- Usar `snake_case` para carpetas y archivos.
- Los documentos `.md` deben incluir un encabezado YAML con metadatos.
- Los archivos en `downloads/` y `logs/` deben estar excluidos de versionado (`.gitignore`).
- Mantener cada carpeta lo más atómica y autocontenida posible.
- Idealmente cada script tiene su `README.md` asociado en `scripts/`.

## 🧩 Ventajas

- Modularidad completa y portabilidad.
- Fácil integración con ALMA_RESIST copiando la carpeta dentro de `docs/modules/`.
- Adaptabilidad para proyectos personales de salud, trading, cannabis, IA, etc.

## 📌 Uso recomendado

1. **Inicializar estructura**
   ```bash
   mkdir -p nombre_modulo/{docs/bitacoras,datasets,scripts,notebooks,downloads,tests,logs,config}
   ```

2. **Crear archivos iniciales**
   ```bash
   touch nombre_modulo/docs/{readme.md,version.md}
   ```

3. **Completar metadatos y empezar documentación.**

4. **Mantener una bitácora de avances en `docs/bitacoras/`.**

## Archivo: metodologia_estructura_modular_v1.md
Contenido:
# 🧱 Metodología de Estructura Modular y Carpetas

📅 Versión: 1.0  
🎯 Objetivo: Establecer un estándar profesional y escalable para construir cualquier carpeta, módulo o dominio que desee ser parte del sistema ALMA_RESIST.


## 📦 Estructura Mínima por Módulo

```
[módulo]/
├── README.md               # Descripción general y propósito
├── bitacora.md             # Registro libre de avances, reflexiones, decisiones
├── changelog.md            # Cambios por versión
├── estructura/             # Diagramas, esquemas, arquitectura visual (opcional)
├── docs/                   # Documentación técnica y contextual
│   └── metodologia_local.md   # Cómo funciona este módulo internamente
├── scripts/                # Automatizaciones o utilidades específicas
├── data/                   # Archivos relevantes de entrada/salida
├── versionado/            # Copias congeladas (snapshots o entregas)
│   └── v0.0.0.1/...
```


## 📘 Convenciones

- Nombres de carpetas y archivos en `snake_case`, sin espacios ni tildes.
- `scripts/` debe contener nombres funcionales: `gen_`, `load_`, `test_`.
- Markdown en estilo semántico (con secciones y sintaxis IA-legible).

module: "nombre_modulo"
type: "internal" | "external_domain" | "technical"
version: "0.1"
status: "in_progress"
tags: ["dominio", "tecnico", "legal"]
linked_to: ["ALMA_CORE", "cultivo", "loader"]

## 🔁 Relación con otros protocolos

Esta metodología es invocada desde:

- `Sprint_2.2_Metodologias_Base.md`
- `docs/01_methodologies/Methodology_Index.md`
- Cualquier auditoría futura o proceso de integración

## Archivo: metodologia_interaccion_ia_v1.md
Contenido:
# 🤖 Metodología de Interacción con IA – ALMA_RESIST (v1)

📅 Versión: 1.0  
📁 Archivo: metodologia_interaccion_ia_v1.md  
🎯 Objetivo: Establecer cómo los sistemas de IA (como Alma) deben interactuar con la documentación, estructura y decisiones del sistema ALMA_RESIST de forma segura, trazable y eficiente.


## 🧭 Principios Rectores

1. **Lectura Semántica, No Libre**  
   La IA debe operar sobre documentos que contengan frontmatter YAML válido.

2. **Contexto explícito**  
   La IA debe navegar a través de campos como `linked_to`, `tags`, `type` para entender relaciones.

3. **No modificar sin validación**  
   Toda acción de escritura debe estar aprobada por el operador humano o IA validadora.

4. **Indexación progresiva**  
   Los documentos se indexan como nodos con atributos (tipo, dominio, versión).

module: "core/cli"
type: "core"
domain: "infraestructura"
status: "stable"
tags: ["entrada", "modularidad"]
linked_to: ["resumen", "loader"]
created: "2025-05-21"
version: "0.2"

## 🧠 Modos de Interacción

| Modo         | Descripción                                                      |
|--------------|------------------------------------------------------------------|
| `lector`     | Solo lectura de archivos con YAML válido                         |
| `asistente`  | Sugiere cambios, genera texto, resume, enlaza documentos         |
| `auditor`    | Verifica cumplimiento de estándares y relaciones semánticas      |
| `operador`   | Puede ejecutar acciones, generar ADRs, changelogs, etc. (futuro) |


## 🔄 Relación con otras metodologías

- `metodologia_doc_ia_v2.md`: Define estructura mínima para ser legible por IA
- `metodologia_adr_v2.md`: Relaciona decisiones estructurales con módulos IA-indexables
- `estructura_modular_v2`: Define dónde debe ir cada documento


## 🧾 Changelog

### 2025-05-21
- [v1.0] Creación de protocolo base para interacción IA semántica
- Definición de 4 modos de operación
- Reglas de validación y acciones permitidas


module: metodologias/archivadas/metodologia_sprints_v1
type: core
status: in_progress
created: '2025-05-21'
linked_to:
- metodologia_doc_ia_v2.md


## ✅ Aplicación

Esta metodología se aplica a:

- Mejoras internas o arquitectónicas
- Nuevos módulos o dominios
- Auditorías, migraciones, expansiones
- Cualquier proceso con entregables concretos


## 📋 Estados posibles

| Estado     | Significado técnico                                                      |
|------------|--------------------------------------------------------------------------|
| Activo     | En ejecución                                                             |
| Cerrado    | Finalizado y documentado (impactó changelog, hitos, versión)             |
| Archivado  | Conservado para trazabilidad pero ya sin función activa                 |


## 🧠 Metadatos YAML en cada archivo de sprint

```yaml
```


## 🎯 Objetivo
Texto conciso del propósito del sprint


## 📎 Archivos relacionados
- [ ] core/cli.py
- [ ] changelog.md


## 🔁 Registro Final
- [x] Actualizado changelog.md
- [x] Agregado en hitos.md
- [x] Anotado en lecciones_aprendidas.md
```

## Archivo: _propuesta_v3_doc_ia.md
Contenido:
# 🔭 Propuesta de Implementación Modular – Documentación Humano + IA (v2)

📅 Fecha: 2025-05-21  
📁 Asociado a: `Sprint_2.2_Metodologias_Base`  
🎯 Propósito: Integrar progresivamente una estructura documental semántica IA-friendly que sea viable para un único operador, con capacidad de escalar a automatización parcial.


## 📋 Cambios Introducidos en `metodologia_doc_ia_v2.md`

| Mejora                      | Descripción técnica clave                                                    |
|----------------------------|-------------------------------------------------------------------------------|
| 🔹 Reducción de campos      | De 8 a 4 campos obligatorios (`module`, `type`, `status`, `created`)         |
| 🔹 Campos opcionales        | `domain`, `tags`, `linked_to`, `version` quedan como sugeridos               |
| 🔹 Política de migración    | Etapas 1–2–3 para evitar sobrecarga en documentos existentes                  |
| 🔹 Glosario técnico         | Referencias rápidas para `type`, `domain`, `status`                          |
| 🔹 Comando `alma-cli`       | Especificación base para autocompletar bloques YAML vía CLI con IA           |


## 🧠 Beneficios esperados

- Trazabilidad semántica sin burocracia
- IA como asistente documental real
- Minimización de deuda técnica
- Posibilidad de detección de módulos huérfanos, duplicados o sin versionar


## 🔄 Estado actual

✅ Ya se generó y archivó la metodología v2  
🔜 Pendiente implementación de `alma-cli doc-init`  
🧩 Listo para ser referenciado en próximas decisiones ADR



module: metodologias/propuestas/propuesta_v3_estructura_modular
type: core
status: in_progress
created: '2025-05-21'
linked_to:
- metodologia_doc_ia_v2.md


## ✅ Objetivo

Capturar propuestas de mejora avanzada para evolucionar la metodología de estructura modular hacia una versión 3 más automatizada, escalable y colaborativa, sin aplicarlas inmediatamente.


### 2. Documentación Auto-Generada

- [ ] Incluir plantilla `mkdocs.yml`
- [ ] Agregar guía para despliegue en GitHub Pages
- [ ] Navegación automática basada en `linked_to`, `tags`


### 4. Namespaces Jerárquicos

- [ ] Convención para dominios complejos:
    - `trading/backtesting/`
    - `external/cannabird/`
```yaml
module: "trading:backtesting"
type: "core"
```


### 6. Repositorio de Plantillas (ALMA_TEMPLATES)

- [ ] Crear módulo `alma-templates/` o CLI tipo:
```bash
alma-cli new-module --type technical --name llm_processor
```


### 8. Compatibilidad Multientorno

- [ ] Estandarizar `config/`:
```bash
config/
├── dev/
├── staging/
└── prod/
```

```yaml
env_support: ["dev", "staging"]
```


### 10. Preparación para Colaboradores Futuros

- [ ] Crear `CONTRIBUTING.md` con:
    - Flujo de PR
    - Validación de metadatos
    - Guía para `dev_journal.md`




module: metodologias/propuestas/propuesta_v3_interaccion_ia
type: core
status: in_progress
created: '2025-05-22'
linked_to:
- metodologia_doc_ia_v2.md


## 🔮 Visión futura

- Integración en tiempo real con múltiples agentes (CLI + Chat + Webhook)
- Inferencia automática de `linked_to` por NLP contextual
- Reconocimiento semántico y clustering por dominio (`trading`, `cultivo`, etc.)
- Actualización automática de `status`, `version`, `impact` por commits


## 🛠️ CLI y Automatización

```bash
alma-cli review-missing-context
alma-cli auto-link --domain cultivo
alma-cli summarize-changes --since v2.1
```


## 🌱 Implementación sugerida

Fase 1: IA como auditor+asistente en todos los sprints  
Fase 2: Comandos CLI activos para sugerencia y migración  
Fase 3: Agente autónomo con control limitado (operador validando)

### 2. **Ejemplos de Flujos de Trabajo Autónomos**

```markdown
# docs/ia_workflows/autolink_example.md  
1. IA detecta que `cultivo/riego.md` menciona "fertilización" 3 veces  
2. Sugiere añadir tag `fertilización` y link a `cultivo/fertilizantes.md`  
3. Si el operador aprueba, actualiza YAML automáticamente  
```


### 4. **Transición Gradual de Fases**

```mermaid
graph TD  
  A[Fase 1: Auditor+Asistente] -->|+10 módulos| B[Fase 2: CLI Activo]  
  B -->|+20 módulos| C[Fase 3: Agente Autónomo]  
  C -->|Backup diario| D[Failsafe: Rollback automático]  
```

**Checklist de habilitación**:
- Tests de integración IA al 95%
- Documentación de rollback en `docs/emergency.md`


### 6. **Monitorización de Recursos**

```bash
alma-cli monitor --cpu --memory --graph-complexity
```

**Métricas clave**:
- Tiempo de respuesta IA por módulo
- RAM consumida en inferencias complejas
- Nodos huérfanos en grafo semántico

## Archivo: prompt_technical_ALMA_LOADER_v3.0.2.md
Contenido:
# 🧠 Prompt Técnico ALMA_LOADER v3.0

## 🧭 Roadmap Técnico ALMA_LOADER – Versión Expandida


### 🔷 B. Roadmap Operativo Detallado (vinculado al desarrollo actual)

> Esta sección detalla las tareas concretas, módulos activos y enlaces con los cuadernos digitales. Se actualiza por versión (actual: 3.0.3+).

#### 🎯 Objetivo General

Consolidar un backend modular, seguro y ampliable que actúe como núcleo inteligente de un asistente personal diario. Toda la lógica y estructura se mantiene sintetizada en dos archivos base (`whitepaper` y `prompt técnico`) para máxima claridad e interoperabilidad con modelos de lenguaje. Se prioriza compatibilidad con cuadernos digitales (Obsidian, Shortcuts, Recordatorios).


#### 🧠 Fase 2 – IA Básica y Consultas
- Endpoint `/v1/assistant/consultar`
- Uso de modelo externo para responder con contexto
- Creación de `core/racionalizador.py`
- Prompts funcionales en el prompt técnico
- Nueva sección: “Capas de interacción con IA”


#### 🔐 Fase 4 – Seguridad y Despliegue
- JWT real y múltiples usuarios
- Dockerfile + `docker-compose`
- Endpoint de monitoreo básico
- Telegram + Shortcuts como interfaz liviana


#### 📘 Notas Finales
- Toda evolución queda registrada en el `CHANGELOG.md`
- Se prioriza siempre claridad conceptual antes que escalamiento técnico
## 1. Propósito del Sistema
Este prompt define todas las funciones técnicas, estructuras internas y flujos de interacción del sistema ALMA_LOADER. Su objetivo es que cualquier modelo IA o humano técnico pueda ejecutar, extender o auditar el sistema con claridad total. Consolidado a partir de versiones 2.1.1 y 2.2.0.
El Prompt Técnico: **“enfoque técnico y operacional”**
Para la perspectiva emocional y filosófica del sistema, ver el Prólogo del Whitepaper.”
> 📘 Para entender el propósito humano, los casos de uso y la visión general del sistema,  
> consultá el [Whitepaper de ALMA_LOADER](ALMA_LIBRE/MODULOS/Alma_Loader/alma_loader_v3.0.3/docs/archivos_fundamentales/whitepaper_ALMA_LOADER_v3.0.2.md)

## 2. Módulos Funcionales
- `core_nl.py` – Conversión NL → JSON mediante reglas y patrones
- `validador.py` – Validación con `schema_base.json` y normalización de campos
- `sqlite_storage.py` – Almacenamiento actual, optimizado con JSON1 para consultas internas
- `base_storage.py` – Interfaz abstracta de almacenamiento compatible con múltiples motores
- `vector_storage.py` – Búsqueda semántica con embeddings vía FAISS (alpha)
- `router_atencional.py` – Enrutamiento según intención detectada (acción, reflexión, memoria)
- `resumenes.py` – Generación de resumen en Markdown diario o semanal
- `alma_analytics.py` – Detección de patrones, correlaciones y disparadores
- `gamificacion.py` – Sistema de motivación por puntos, niveles y hábitos (fase 3)

Los módulos de ALMA_LOADER están diseñados para ser independientes y fácilmente intercambiables. A continuación, se indican las principales tecnologías asociadas a cada uno:

### 🛠️ Tecnologías Utilizadas por Módulo

| Módulo                   | Tecnología / Herramienta              |
|--------------------------|--------------------------------------|
| NLP / Parsing            | `regex`, `spaCy` (plan futuro)       |
| Vectorización semántica | `sentence-transformers`, `FAISS`     |
| Almacenamiento           | `SQLite` (con JSON1), `FAISS` (alpha)|
| Visualización / Testing  | `pytest`, `Mermaid` (para diagramas) |
| Relaciones semánticas    | `dict`, relaciones cruzadas (`Neo4j`, `networkx` – futuro) |


## 3. JSON Schema de Memoria
```json
{
  "id": "MEM-TRD-2025-XXXX",
  "categoria": "TRD",
  "contenido": "texto plano",
  "tags": ["#btc", "#reflexión"],
  "resumen_inferido": "...",
  "embedding_id": "EMB-abc123",
  "vector": [0.123, 0.987, ...],
  "intencion_detectada": "registro",
  "origen_input": "usuario",
  "relaciones": [
    { "tipo": "temporal", "target_id": "MEM-TRD-2025-XXXX", "peso": 0.8 }
  ]
}
```

> Este prompt técnico permite que cualquier IA ejecute acciones correctas dentro de ALMA_LOADER sin ambigüedades ni errores de interpretación. Complementa al whitepaper 3.0 (explicativo y estratégico).

## 9. Testing y Validaciones

### 🧪 Test Unitario – Validación de Memoria

Este test permite verificar que el esquema base JSON acepte estructuras válidas y rechace incorrectas. Se usa como prueba mínima para `validador.py`.

```python
def test_validar_memoria():
    memoria_valida = {
        "id": "MEM-TRD-2025-05-06-001",
        "categoria": "TRD",
        "contenido": "Hoy operé en BTC y me sentí confiado",
        "tags": ["#btc", "#emoción:confianza"]
    }
    assert validar_esquema(memoria_valida) == True
```

Este tipo de test puede ejecutarse con `pytest`, `unittest`, o integrarse en un pipeline de verificación previa al guardado.

### 🧪 Test Unitario – Vectorización Semántica

Este test valida que la función de embeddings esté operativa y produzca un vector válido (usualmente de 384 o 768 dimensiones, según modelo).

```python
def test_vectorizacion():
    texto = "Hoy operé bajo presión y me sentí impulsivo."
    vector = generar_embedding(texto)
    
    assert isinstance(vector, list)
    assert len(vector) >= 128
    assert all(isinstance(x, float) for x in vector)
```

> Este test puede servir tanto para debug local como para verificar integridad del motor FAISS en producción.

## 10. Relaciones entre Memorias – Grafo Dirigido

ALMA_LOADER permite establecer vínculos explícitos entre memorias usando el campo `relaciones`. Esto habilita un grafo dirigido de conocimiento interno.

Cada relación incluye:
- `tipo`: naturaleza de la relación (ej: `temporal`, `causal`, `emocional`, `refuerzo`)
- `target_id`: ID de la memoria relacionada
- `peso`: valor entre 0 y 1 que indica la fuerza del vínculo

### 📄 Ejemplo:
```json
"relaciones": [
  { "tipo": "causal", "target_id": "MEM-TRD-2025-05-04-002", "peso": 0.85 },
  { "tipo": "temporal", "target_id": "MEM-TRD-2025-05-03-001", "peso": 0.6 }
]
```

Este grafo puede analizarse para:
- Descubrir patrones encadenados (causas → consecuencias)
- Medir recurrencia o acumulación emocional
- Visualizar el recorrido mental de un tema

### 🛠️ Futuras integraciones:
- `networkx` (Python) para análisis de grafos
- `Neo4j` para persistencia de relaciones complejas
- Mermaid o D3.js para visualización gráfica

> El objetivo es pasar de registros aislados a una red dinámica de aprendizaje personal.

## 🔌 Integración con Módulos Externos

ALMA_LOADER está diseñado para operar como núcleo de memoria e inteligencia semántica para múltiples aplicaciones.

Esta versión 3.0.2 introduce una estructura preparada para la futura integración de módulos externos. Cada uno de estos módulos podrá interactuar con el sistema a través de sus interfaces y funciones expuestas.

### Ejemplos de módulos potenciales (en evaluación):
- 📊 Analizador de Trading Emocional
- 🌱 Gestor Inteligente de Cultivo
- 📔 Bitácora Personal Automatizada
- 🧠 Asistente de Decisiones Estratégicas
- 💰 Controlador de Fondos y Riesgo

> En futuras versiones, cada módulo tendrá su documentación (`README`) y prompt local, conectado a ALMA_LOADER como backend de memoria.

Esta sección será actualizada a medida que se confirmen las integraciones.

### 4.1 🌐 API REST (Diseño Futuro)

ALMA_LOADER está preparado para exponer una API REST que permita la integración con interfaces externas, aplicaciones móviles, dashboards analíticos, asistentes de voz y automatizaciones.

La API será desarrollada con FastAPI y seguirá estándares modernos (OpenAPI 3.1).

### 🔌 Endpoints planeados (versión inicial)

| Método | Endpoint             | Descripción breve                              |
|--------|----------------------|-------------------------------------------------|
| POST   | /memorias            | Registra una nueva memoria                     |
| GET    | /memorias            | Devuelve todas las memorias                    |
| GET    | /memorias/{id}       | Busca una memoria por ID                       |
| GET    | /memorias/search     | Búsqueda semántica por contenido o tags        |
| POST   | /memorias/relacionar | Enlaza dos memorias existentes                 |
| GET    | /tags                | Lista todos los tags usados                    |
| GET    | /memorias/recientes  | Devuelve últimas N memorias registradas        |

### 🧩 Ejemplo de integración futura

```http
POST /memorias
Content-Type: application/json

{
  "id": "MEM-TRD-2025-05-06-001",
  "categoria": "TRD",
  "contenido": "Operé ETH/USD con 3% de riesgo tras dormir poco.",
  "tags": ["#fatiga", "#riesgo", "#trading"]
}
```

Este input será validado con `schema_base.json`, almacenado vía `SQLiteStorage`, vectorizado (FAISS) y procesado por `on_memoria_guardada()` si aplica.

> Esta API será lanzada como parte de la versión 3.1.x de ALMA_LOADER.
## 5. Diagramas del Sistema
```mermaid
flowchart TD
    input["🧑 Usuario o IA"] --> nl["core_nl.py"]
    nl --> validador["validador.py"]
    validador --> router["router_atencional.py"]
    router --> storage["sqlite_storage / vector_storage"]
    router --> resumenes["resumenes.py"]
    resumenes --> output["📄 Markdown / Dashboard"]
    storage --> analytics["alma_analytics.py"]
    analytics --> output
```

## 6. Escalabilidad y Visión Futura
- Vectorización total y enlaces entre memorias (grafos)
- Reemplazo de SQLite por motores orientados a relaciones (Neo4j)
- Integración con asistentes personales vía voz, API y web
- Memorias multiusuario con capas de privacidad

## 7. Recomendaciones de Integración
- El sistema espera entradas en lenguaje natural o JSON válido
- Cada módulo puede operar por separado (desacoplamiento limpio)
- Ideal para integrarlo como backend de un asistente IA
- DeepSeek, GPT o interfaces custom pueden usarlo como núcleo de memoria conversacional
## 8. Comandos Útiles – Modo Asistente

ALMA_LOADER puede ser utilizado como un asistente conversacional desde cualquier interfaz (terminal, Telegram, Shortcuts, GPT, etc.). A continuación, algunos ejemplos de uso:

### 📘 Comandos de Registro
- `/nueva Hoy gané $100 operando BTC con alta ansiedad`
- `/nueva Me sentí estancado y sin claridad esta semana`

### 📙 Comandos de Acción
- `/accion Meditar 15 minutos después del mercado`
- `/accion Ajustar riesgo a 1% esta semana`

### 📗 Comandos de Reflexión
- `/reflexion Me doy cuenta que opero peor cuando duermo poco`
- `/reflexion Revisar trades similares a MEM-TRD-2025-04-10`

### 📕 Comandos de Consulta
- `/resumen semana`
- `/alertas activas`
- `/recomendar memoria relacionada con ansiedad y sobreoperación`

> Cada uno de estos comandos será procesado y transformado en memoria, acción o reflexión según el módulo de atención.


## 🧭 Roadmap General Estratégico – ALMA_LOADER Post v3.0.3

### 🎯 Objetivo General

Consolidar un backend modular, seguro y ampliable que actúe como núcleo inteligente de un asistente personal diario. Toda la lógica y estructura se mantiene sintetizada en dos archivos base (`whitepaper` y `prompt técnico`) para máxima claridad e interoperabilidad con modelos de lenguaje. Se prioriza compatibilidad con cuadernos digitales (Obsidian, Shortcuts, Recordatorios).


### 🧠 Fase 2 – IA Básica y Consultas
- Endpoint `/v1/assistant/consultar`
- Uso de modelo externo para responder con contexto
- Creación de `core/racionalizador.py`
- Prompts funcionales en el prompt técnico
- Nueva sección: “Capas de interacción con IA”


### 🔐 Fase 4 – Seguridad y Despliegue
- JWT real y múltiples usuarios
- Dockerfile + `docker-compose`
- Endpoint de monitoreo básico
- Telegram + Shortcuts como interfaz liviana


### 🧩 Notas Finales
- Toda evolución queda registrada en el `CHANGELOG.md`
- Se prioriza siempre claridad conceptual antes que escalamiento técnico

## 🧾 Anexo Histórico – Evolución del Sistema

> Registro consolidado de avances funcionales y técnicos por versión (v3.0.0 → v3.0.2).


#### 🚀 Versión 3.0.1 – Profesionalización Técnica

### ✅ Objetivos:
- Incluir elementos técnicos reales que permitan operar y testear el sistema.
- Preparar el motor para trabajar con FAISS, SQLite y validaciones avanzadas.

### 🛠️ Implementaciones:
- Ejemplo real de test unitario para validación de memorias.
- Agregado de tabla de tecnologías usadas (spaCy, sentence-transformers, FAISS, SQLite).
- Caso real de regla dinámica en `reglas_dinamicas.json`.
- Documentación de la coexistencia entre SQLite y FAISS (con `embedding_id`).
- Refuerzo de consistencia entre módulos en prompt y whitepaper.


### 🔚 Resultado

> ALMA_LOADER hoy es un sistema **modular, documentado, integrable y escalable** que puede:
- Operar como backend semántico de cualquier app (cultivo, trading, bitácoras).
- Ser entendido por humanos o IAs con solo 2 archivos centrales.
- Adaptarse a futuras versiones de forma incremental y trazable.

module: mvp/resumen_mvp
type: core
status: in_progress
created: '2025-05-22'
linked_to:
- metodologia_doc_ia_v2.md


## 🧠 ¿Qué es ALMA_RESIST?

ALMA_RESIST es un entorno operativo portable, antifrágil y orientado a terminal, diseñado para ser la base técnica de un sistema de IA distribuido, resiliente y autónomo. Su propósito es servir como núcleo funcional de trabajo local con IA, memoria extendida y sincronización con entornos espejo.


## ⚙️ Componentes Implementados

| Componente               | Estado   | Observaciones                                       |
|--------------------------|----------|-----------------------------------------------------|
| `log_writer.py`          | ✅        | Log funcional, con metadatos completos              |
| `log_crypto.py`          | ✅        | Log cifrado AES/ChaCha funcional                    |
| `hitos.md`               | ✅        | Estructura con versión 0.0.0.1                      |
| `changelog.md`           | ✅        | Control de cambios detallado                        |
| `auditoria_estructura.md`| ✅        | Evaluación crítica de la estructura del sistema     |
| `resumen_secciones.md`   | ✅        | Estado actual por módulo                            |
| `docs/versiones/README.md`| ✅       | Estandarización de versiones congeladas             |


## 🚧 Consideraciones

El MVP no busca ser utilizable por terceros aún. Su propósito es **sentar las bases técnicas**, validar estructura y establecer estándares. Todo lo construido está orientado a escalarse, no a entregarse.


## 🔗 Relacionado

- [[13cc/registros/hitos]]
- [[13cc/dev/changelog]]
- [[ALMA_RESIST/logs/auditorias/auditoria_estructura]]
- [[ALMA_RESIST/docs/resumen_secciones]]
  

## 🧠 Qué incluye esta versión

Sprint de consolidación metodológica:
- Implementación de CLI funcional (core/cli.py)
- Modularización de comandos y validación por test
- Sistema de logging estructurado y logs IA-trazables
- Definición y registro de 6 metodologías operativas
- Organización estandarizada de `/docs/` para navegación IA

## 🔗 Relación con componentes anteriores

- Continúa la línea base establecida en `v0.0.0.1`
- Todos los módulos actuales siguen la metodología modular definida
- La arquitectura es ahora indexable y trazable por IA local

📂 Ubicación recomendada:
`docs/mvp/resumen_mvp_v0.0.0.2.md`
  

### ✅ Alcance logrado

- Se definieron y documentaron 6 metodologías oficiales:
  - Estructura modular
  - Ciclos de sprint
  - Versionado y backups
  - Documentación legible por IA
  - Registro de decisiones (ADR)
  - Interacción estructurada con sistemas IA

- Todas las metodologías quedaron reflejadas en:
  - `/docs/01_methodologies/` (activas)
  - `_archivadas/` (anteriores)
  - `_propuestas/` (evoluciones futuras)


### 🧩 Impacto en el sistema

- Nueva organización del índice de metodologías (`Methodology_Index.md`)
- Actualización del `README.md` general
- Preparación completa para automatización futura

## Resumen MVP – Sprint 2.3

**Objetivo alcanzado:** Consolidación y automatización del sistema de metadatos

**Componentes clave:**
- `fix_metadata.py v4`: Generación y validación automática de YAML en documentos
- `force_snake_case_modules.py`: Normalización de estructura semántica para compatibilidad IA
- `validate_docs.py`: Validación estricta de integridad documental
- `integrar_nuevo_archivo.sh`: Automatización unificada del flujo de integración

**Resultado:**
El sistema de documentación cuenta ahora con una base robusta, consistente y lista para escalar con módulos de IA y procesos colaborativos.


### ✅ Alcance logrado

- Creación y estandarización de plantillas en YAML (`docs/estructura_doc`)
- Implementación de testing base: CLI y validador de metadatos
- Consolidación de documentación viva (`TODO.md`, `.project.md`)
- Registro del snapshot con hash SHA y firma técnica
- Organización profesional del sistema documental para escalar con IA


✅ Sprint cerrado formalmente. Documentación preparada para expansión futura.


## 🏁 Consolidación del MVP – Sprint 2.5

- 📦 Estructura modular mínima completada
- 📄 Documentación semántica funcional
- 🧠 Compatibilidad verificada con modelos IA
- 🛠️ Validación automatizada mediante scripts integrados
- 📚 Entrada técnica unificada (`prompt_tecnico_base.md`)
- 🧭 El sistema puede funcionar autónomamente desde CLI, con IA o como repositorio auditable

> Estado: **MVP estable** – listo para evolución


module: roadmap_tecnico
type: core
status: in_progress
created: '2025-05-20'
linked_to:
- metodologia_doc_ia_v2.md


## 📌 **Fase 1: Desarrollo Inicial (MVP Chat-CLI)**
### Sprint 1 – Chat Básico + Logs
- [ ] Implementar CLI interactiva con LLM local (`cli.py`).
- [ ] Guardar logs en `.md`/`.json` en `ALMA_RESIST/logs/`.
- [ ] Comandos básicos: `!reset`, `!help`, `!exit`.
- [ ] Pruebas de usabilidad con prompts simples (10+ usuarios beta).
- [ ] **Documentación:** Crear `docs/cli_guide.md` (comandos básicos).

### Sprint 2 – Persistencia + ALMA_LOADER Inicial
- [ ] Almacenar historial en SQLite cifrado (`user/history.db`).
- [ ] Script ETL diario (`ALMA_LOADER/etl_daily.py`).
- [ ] Comandos: `!memoria [tema]`, `!buscar "[texto]"`.
- [ ] **Métrica:** Tiempo de respuesta `< 2s` en consultas.


## 📌 **Fase 3: Optimización y Escalabilidad**
### Sprint 6 – Feedback y Optimización
- [ ] Sistema de feedback: `¿Fue útil? [Sí/No]`.
- [ ] Ajustar sugerencias basadas en `logs/feedback.json`.
- [ ] Refinar prompts del LLM (`ALMA_SERVER_LLM/prompts/`).
- [ ] **Documentación:** `docs/feedback_analysis.md`.

### Sprint 7 – Integración GPU/ONNX
- [ ] Soporte para modelos ONNX en GPU (`llm_onnx.py`).
- [ ] Optimizar inferencia con TensorRT (si NVIDIA GPU detectada).
- [ ] **Métrica:** `>3x` aceleración vs CPU.

### Sprint 8 – DuckDB y Análisis Avanzado
- [ ] Migrar análisis históricos a DuckDB (`ALMA_LOADER/duckdb_analytics.py`).
- [ ] Consultas complejas: `!analizar "uso de RAM últimos 7 días"`.
- [ ] **Documentación:** `docs/duckdb_integration.md`.

### Sprint 9 – Pruebas de Resiliencia
- [ ] Simular corrupción de logs (`tests/corrupt_logs.py`).
- [ ] Pruebas de inyección SQL en bases locales.
- [ ] Validar modo supervivencia bajo estrés térmico.
- [ ] **Métrica:** Recuperación en `< 30s` tras fallo.


## 🔗 **Archivos Relacionados en Obsidian**
- [[ALMA_RESIST-idea_base]]  
- [[ALMA_RESIST-PROMPT_TECNICO]]  
- [[ALMA_RESIST-Whitepaper]]  

### 📎 Anexos


-  [[roadmap_tecnico_detallado.pdf|🧾 PDF – Roadmap Técnico Detallado (v0.0.1)]]




**✨ Copia este contenido en un nuevo archivo .md en Obsidian y usa checkboxes ( [ ] → [x] ) para marcar el progreso.**

## Archivo: context_tracker_request.md
Contenido:
# 🧠 Solicitud de Implementación – `context_tracker.py` – Sprint 2.6 – ALMA_RESIST

## 🎯 Objetivo

Implementar el módulo `context_tracker.py`, encargado de registrar y mantener un historial contextual estructurado de interacciones en el servidor ALMA_RESIST. Este historial será clave para futuras reflexiones automáticas, reconstrucción de diálogos y razonamiento semántico.


## 🧪 Ejemplo de uso

```python
from integration.context_tracker import ContextTracker

tracker = ContextTracker()
tracker.track_interaction("¿Qué es la resiliencia?", "La capacidad de...", {"modelo": "mistral"})
historial = tracker.get_history(5)
```

## Archivo: log_writer_request.md
Contenido:
# 🧠 Solicitud de Implementación – `log_writer.py` – Sprint 2.6 – ALMA_RESIST

## 🎯 Objetivo

Implementar el módulo `log_writer.py`, encargado de registrar eventos estructurados del sistema ALMA_RESIST en archivos de log en formato JSONL.

Este módulo es parte del sistema de trazabilidad segura y debe integrarse con los componentes del servidor LLM.


## 🧪 Ejemplo de uso

```python
from utils.log_writer import log_event, write_log

evento = log_event("INFO", "Inicio del servidor LLM", "main")
ok = write_log(evento)
```

## Archivo: main_py_request.md
Contenido:
# 🧠 Solicitud de Implementación – `main.py` – Sprint 2.6 – ALMA_RESIST

## 🎯 Objetivo

Implementar el archivo `main.py` del módulo `llm_server`, que actuará como servidor API usando FastAPI. Este archivo forma parte del Sprint 2.6 del proyecto ALMA_RESIST.


## 🔧 Detalles Técnicos

- El archivo debe ubicarse en: `core/llm_server/main.py`
- `ModelWrapper` ya está implementado parcialmente en `model_wrapper.py`
- El endpoint debe validar entrada con Pydantic
- No debe haber lógica del modelo en `main.py`, solo orquestación


## 🧪 Ejemplo de uso

```bash
curl -X POST http://localhost:8000/responder -H "Content-Type: application/json" -d '{"prompt": "¿Quién fue Alan Turing?"}'
```

Esperado:

```json
{
  "respuesta": "Alan Turing fue un matemático británico considerado el padre de la computación moderna..."
}
```


module: prompts/memory_graph_request
type: core
status: in_progress
created: '2025-05-26'
linked_to:
- metodologia_doc_ia_v2.md


## 📘 Requisitos

### Clase: `MemoryGraph`

- Métodos esperados:
  - `add_node(concept: str) -> str`  
    Agrega un nodo único al grafo semántico.
  - `create_edge(from_concept: str, to_concept: str, weight: float = 1.0) -> None`  
    Crea una relación ponderada entre dos conceptos.
  - `get_related(concept: str, top_k: int = 5) -> list[str]`  
    Recupera los conceptos más relacionados a partir de pesos acumulados.
  - `export_graph(file_path: str) -> None`  
    Exporta el grafo a JSON o GraphML para visualización futura.

### Condiciones:
- Guardar estructura internamente como diccionario `{ nodo: { nodo_vecino: peso } }`
- Prevenir duplicados en nodos
- Incrementar peso si la relación ya existe
- Guardar el grafo en archivo local `memory_graph.json`
- Preparado para extender a FAISS o embedding vectorial en el futuro


## 📎 Contexto

- Sprint: 2.6 – LLM Server
- Integra datos desde: `context_tracker`, `TransportLayer`
- Fundamento del módulo de reflexión semántica de ALMA


module: prompts/model_wrapper_request
type: core
status: in_progress
created: '2025-05-26'
linked_to:
- metodologia_doc_ia_v2.md


## 📘 Requisitos

### Clase: `ModelWrapper`

- Métodos requeridos:
  - `__init__(self, model_path: str, quantization: str = "Q4")`  
    Inicializa el wrapper y prepara configuración del modelo.
  - `load_model(self)`  
    Carga el modelo desde el archivo `.gguf` utilizando `llama_cpp.Llama`.
  - `generate(self, prompt: str) -> str`  
    Genera texto a partir de un prompt usando el modelo cargado.
  - `is_loaded(self) -> bool`  
    Devuelve `True` si el modelo está cargado correctamente.
  - `get_model_info(self) -> dict`  
    Devuelve un resumen con nombre del modelo, tamaño del contexto, tokens usados, etc.

### Condiciones:
- Usar la librería `llama-cpp-python` (`pip install llama-cpp-python`)
- Soportar modelos cuantizados `.gguf`, preferentemente Q4
- Manejar errores si el modelo no está cargado
- Ser compatible con FastAPI y asincronía de `main.py` (aunque esta clase puede ser sin `async`)
- Preparar para trabajar con modelos como Mistral 7B o TinyLlama


## 📎 Contexto

- Este wrapper será invocado desde el endpoint `/responder` del archivo `main.py`
- Sprint: 2.6 – LLM Server
- Arquitectura basada en idea base `0.0.0.4.1`


module: prompts/prompt_add_linked_to_minimo
type: core
status: in_progress
created: '2025-05-23'
linked_to:
- metodologia_doc_ia_v2.md


# 🧠 Prompt – Generador de Script de Corrección linked_to

Quiero un script en Python llamado `add_linked_to_minimo.py` que recorra todos los archivos `.md` dentro de un directorio (ej: ./docs).

## ✅ El script debe:

1. Leer el bloque YAML de cada archivo.
2. Verificar si el campo `type` es `"core"`.
3. Si el documento **no tiene `linked_to`**, debe agregar:

```yaml
linked_to:
  - metodologia_doc_ia_v2.md
```

4. Mantener los campos existentes. No sobreescribir nada útil.
5. Crear un **backup** del archivo antes de modificarlo (guardar en `./backup_linked_to/FECHA/`).
6. Mostrar por consola qué archivos fueron modificados.
7. Ignorar los archivos que ya tienen `linked_to`.


## 🎯 Objetivo

Este script ayudará a corregir más de 90 archivos `.md` que fallan la validación por no tener `linked_to`, cuando son `type: core`. El valor `metodologia_doc_ia_v2.md` es un enlace válido y genérico para normalización mínima.


module: prompts/prompt_alma_cli_v0_0_0_4
type: core
status: in_progress
created: '2025-05-26'
linked_to:
- metodologia_doc_ia_v2.md


## 🎯 Objetivo del CLI

Centralizar la ejecución de todas las tareas de validación, reparación, estandarización y auditoría semántica bajo un solo comando:

```bash
python alma-cli.py <comando> [opciones]
```


## 📁 Estructura esperada

```
alma-cli.py
/docs
/scripts
/logs/auditorias/
    auditoria_YYYYMMDD_HHMM_sprint_X.md
```

module: docs/01_methodologies/metodologia_sprints_v2
type: core
status: in_progress
created: 2025-05-24
linked_to:
  - metodologia_doc_ia_v2.md

## ✅ Reglas de validación

- `module` debe reflejar la ruta relativa y estar en snake_case
- `type` debe ser uno de: `core`, `tool`, `external`, `integration`, `draft`
- `status`: `in_progress`, `stable`, `deprecated`
- `created`: formato `YYYY-MM-DD`
- Si `type == core`, `linked_to` es obligatorio
- Si `domain` está definido, debe estar también en `tags`


## 🧪 Ejemplo de uso

```bash
# Validar documentos
python alma-cli.py validate --path ./docs --verbose

# Corregir campos YAML con backup
python alma-cli.py fix-metadata --backup

# Normalizar nombres de módulo
python alma-cli.py enforce-snakecase

# Agregar linked_to donde falta
python alma-cli.py add-linked-minimo --dry-run

# Ejecutar pipeline completo de limpieza
python alma-cli.py auto-fix --backup --verbose
```


## 1. Reorganización de Secciones

### ✅ Cambio
Mover la sección 📁 Estructura esperada antes de ⚙️ Subcomandos a integrar.

### 💡 Justificación
Ayuda a contextualizar la estructura de archivos antes de describir los comandos que interactúan con ella, mejorando la coherencia lógica.


### ✍️ Mejora en `batch-update`
Añadir ejemplo de uso:

```bash
# Actualizar campos en lote (ej: añadir `domain` a todos los archivos de tipo `core`)
python alma-cli.py batch-update --filter-type core --set-field domain:ai --dry-run
```

**Justificación:** Clarifica el uso avanzado del comando y su flexibilidad.


## 4. Documentación de Dependencias

### ➕ Sección: 📦 Dependencias

```markdown
## 📦 Dependencias
- `PyYAML` para análisis de bloques YAML.
- `python-slugify` para normalizar snake_case.
```

**Justificación:** Informa a los desarrolladores sobre las bibliotecas externas requeridas, evitando errores de importación.


## 6. Ejemplos Completos

### ➕ Ejemplo para `report`

```bash
# Generar informe en formato JSON
python alma-cli.py report --output-format json
```

**Justificación:** Demuestra cómo usar salidas alternativas (JSON) para integración con otras herramientas.


## 8. Extensibilidad del Proyecto

### ➕ Nota: Contribuir

```markdown
> 💡 **Contribuir**: Este CLI es modular. Para añadir nuevos subcomandos, implemente funciones en `/scripts` y regístrelas en `alma-cli.py`.
```

**Justificación:** Fomenta la colaboración y extensión del proyecto por parte de la comunidad.

## Archivo: prompt_base_cli_modular_v2.md
Contenido:
# 🧠 Prompt Técnico – CLI Modular ALMA_RESIST (v2, sin cmd.Cmd)


## ⚙️ Requisitos funcionales

- Al ejecutar `python core/cli.py`, debe iniciarse un prompt tipo:
  ```
  alma>
  ```
- El usuario puede ingresar comandos como:
  - `!ayuda`
  - `!salir`
  - `!resumir "texto"`
  - `!buscar_memoria "tag"`
- Cada comando se define como una función externa en un archivo separado dentro de `commands/`.


## 🔧 Requisitos técnicos

- `core/cli.py` debe actuar como un **router** de comandos:
  - Lee entrada del usuario (`input`)
  - Separa comando (`!comando`) de argumentos
  - Busca en un diccionario cargado dinámicamente desde `commands/`
  - Ejecuta la función `run(args)` correspondiente
- Si el comando no existe, debe mostrar un mensaje de error.
- Debe incluir comando `!ayuda` que imprima los comandos disponibles (basado en las claves del router).


## 🔐 Restricciones

- **No usar `cmd.Cmd`, argparse, click ni frameworks externos.**
- Todo debe funcionar con funciones planas (`def run(args):`)
- El sistema debe ser extensible: para agregar un comando, basta con crear un archivo `.py` con función `run(args)`.


## 🧠 En resumen

Implementar un CLI minimalista, sólido y extensible para ALMA_RESIST, basado en arquitectura modular y sin dependencias mágicas. Este CLI debe estar listo para integrarse a IA local, logs y memoria a futuro.


module: prompts/prompt_chat_0_0_1
type: core
status: in_progress
created: '2025-05-17'
linked_to:
- metodologia_doc_ia_v2.md


## 🧭 Instrucción Final para GPT-4.5

Como IA Copiloto, desarrollá un roadmap técnico **usando `ALMA_LIBRE/` e `idea_base_0.0.9.md` como base conceptual, no estructural**. Tu tarea incluye:

1. **Roadmap técnico realista (3–6 meses)**  
   - Sprint por sprint (tablas markdown con hipervínculos)  
   - Subtareas de 2–4h con justificaciones técnicas  

2. **Validación multiplataforma y por arquitectura**  
   - x86_64, ARMv8, RISC-V  
   - Script `test_arch.sh` detecta y ejecuta tests optimizados  
   - Reporte comparativo en `docs/benchmarks_arch.md`

3. **Políticas de energía avanzadas**  
   - `taskset`, `cpufreq-set`, I/O throttling  
   - Activación automática por condiciones: batería <15%, CPU >80°C, swap >20%  
   - Desactivación de módulos no críticos  

4. **Monitoreo predictivo en tiempo real**  
   - `alma_monitor.py`: alertas por RAM, temperatura, uso de CPU  
   - IA que propone mitigaciones automáticas

5. **Autoevaluación y aprendizaje evolutivo**  
   - `alma_auto_eval.py`: compara métricas entre sprints  
   - IA genera sugerencias + benchmarks + próximos pasos  

6. **Integración de tecnologías emergentes (roadmap ONNX/TensorRT)**  
   - Sprint 6: Wrapper C++ GPU, validación de precisión  
   - Sprint 7: Quantización dinámica, soporte NPU con OpenVINO  

7. **Simulaciones extremas**  
   - Corrupción de logs + headers ilegibles  
   - SQL injection sintética  
   - Pérdida de refrigeración → modo survival 30% CPU  
   - Fallo 2/3 nodos de cluster (evaluar degradación)

8. **Documentación inteligente y ejecutable**  
   - `docs/reporte_sprint.md`: KPIs, gráficos interactivos Plotly, código rastreable  
   - `docs/lecciones_aprendidas.md`: refactors, fallos, herramientas descartadas  
   - `docs/arquitectura_evolutiva.md`: cómo integrar nuevas tecnologías sin romper compatibilidad

9. **Migración y actualización automática**  
   - Script `alma_update.sh` para mover config/logs/versiones  
   - Checklist retrocompatibilidad (versión previa a actual)


## 🔐 Detalles Técnicos Clave

- 🛠️ `test_arch.sh`: Detecta arquitectura y lanza pruebas optimizadas
- 📈 `alma_monitor.py`: RAM, CPU, disco, temperatura → alertas
- 🧠 `alma_auto_eval.py`: Análisis entre sprints, IA sugiere cambios
- 🧪 `generate_synthetic_data.py`: 10k mensajes, modelos rotos, ataques sintéticos
- 🔄 `alma_update.sh`: Migración de configuraciones entre versiones

