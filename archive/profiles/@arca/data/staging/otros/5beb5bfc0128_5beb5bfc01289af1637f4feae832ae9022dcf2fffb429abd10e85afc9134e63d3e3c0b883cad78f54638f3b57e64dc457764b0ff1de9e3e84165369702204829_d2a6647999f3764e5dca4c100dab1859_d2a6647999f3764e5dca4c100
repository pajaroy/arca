import pytest
from unittest.mock import Mock, patch
from core.llm_server.model_wrapper import ModelWrapper
import os
import logging

# Fixture para mockear llama.cpp y evitar dependencias reales
@pytest.fixture
def mock_llama():
    with patch("llama_cpp.Llama") as mock_llama_cls:
        mock_instance = Mock()
        mock_instance.create_completion.return_value = {
            "choices": [{"text": "Respuesta generada por el modelo"}]
        }
        mock_instance.__llama_version__ = "0.1.0"
        mock_instance._params = Mock(n_params=7_000_000_000)
        mock_llama_cls.return_value = mock_instance
        yield mock_llama_cls, mock_instance

# Fixture para instancia de ModelWrapper con modelo válido
@pytest.fixture
def valid_model_wrapper(mock_llama):
    model_path = "models/mock_model.gguf"
    os.makedirs("models", exist_ok=True)
    open(model_path, "w").close()  # Crear archivo dummy
    return ModelWrapper(model_path, quantization="Q4")

# Tests de carga de modelo
def test_model_loading_success(valid_model_wrapper, mock_llama):
    mock_llama_cls, mock_instance = mock_llama
    valid_model_wrapper.load_model()

    assert valid_model_wrapper.is_loaded(), "El modelo debería estar cargado"
    mock_llama_cls.assert_called_once()
    assert mock_instance == valid_model_wrapper._model

def test_model_loading_failure():
    with pytest.raises(FileNotFoundError):
        ModelWrapper("ruta/inexistente.gguf").load_model()

# Tests de generación de texto
def test_text_generation(valid_model_wrapper, mock_llama):
    valid_model_wrapper.load_model()
    prompt = "¿Cuál es el sentido de la vida?"
    response = valid_model_wrapper.generate(prompt)

    assert isinstance(response, str), "La respuesta debe ser un string"
    assert len(response) > 10, "Respuesta demasiado corta"
    valid_model_wrapper._model.create_completion.assert_called_once_with(
        prompt=prompt,
        max_tokens=512,
        temperature=0.7,
        top_p=0.95,
        repeat_penalty=1.1,
        echo=False
    )

def test_generation_without_loaded_model(valid_model_wrapper):
    with pytest.raises(RuntimeError, match="no cargado"):
        valid_model_wrapper.generate("Test")

# Tests de metadatos y estado
def test_model_info(valid_model_wrapper, mock_llama):
    valid_model_wrapper.load_model()
    info = valid_model_wrapper.get_model_info()

    assert info["nombre"] == "mock_model.gguf"
    assert info["cuantización"] == "Q4"
    assert info["parametros"] == "7.0B"

# Test de rendimiento (requiere pytest-benchmark)
@pytest.mark.benchmark
def test_generation_performance(valid_model_wrapper, benchmark, mock_llama):
    valid_model_wrapper.load_model()
    benchmark(valid_model_wrapper.generate, "Prompt de prueba")

# Test de inicialización con parámetros inválidos
def test_invalid_quantization():
    with pytest.raises(ValueError):
        ModelWrapper("models/mock_model.gguf", quantization="INVALID")

# Verificación de logging
def test_error_logging(caplog):
    with pytest.raises(FileNotFoundError):
        ModelWrapper("ruta_falsa.gguf").load_model()

    assert "Error cargando modelo" in caplog.text

# Limpieza post-tests
def teardown_module():
    if os.path.exists("models/mock_model.gguf"):
        os.remove("models/mock_model.gguf")
    os.rmdir("models")
