# ðŸ§  ALMA_RESIST â€“ Servidor LLM Local (Base TÃ©cnica)

## ðŸŽ¯ Objetivo

Montar un servidor de modelos LLM que funcione **de forma local, offline y automÃ¡tica** en el entorno **ALMA_RESIST** (disco Toshiba). Este servidor recibirÃ¡ consultas desde un cliente CLI por terminal y serÃ¡ completamente portable a otros nodos del sistema (ALMA_CORE, pendrive, etc.).


### 2. EjecuciÃ³n AutomÃ¡tica

- Scripts `.sh` + archivos `.desktop` en `~/.config/autostart/`
- Alternativa pro: configuraciÃ³n con `systemd` para persistencia y monitoreo
- Arranca automÃ¡ticamente al prender la PC sin GUI ni navegador


### 4. Estructura de Carpetas del MÃ³dulo

```plaintext
ALMA_SERVER_LLM/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ llm_model.json          # Define modelo y parÃ¡metros
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ chat_log.md             # Guarda los chats
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_llm_server.sh     # Inicia el servidor
â”‚   â””â”€â”€ start_llm_chat.sh       # Cliente CLI
â”œâ”€â”€ system/
â”‚   â””â”€â”€ autostart/
â”‚       â”œâ”€â”€ start_llm_server.desktop
â”‚       â””â”€â”€ start_llm_chat.desktop
```


## ðŸ§± Modularidad y Portabilidad

- Totalmente ejecutable desde cualquier PC con Linux
- DiseÃ±ado para operar sin entorno grÃ¡fico
- Permite reemplazo de modelos, motor o backend sin romper compatibilidad
- Estructura fija y documentada para ALMA_RESIST, ALMA_CORE y dispositivos portables

