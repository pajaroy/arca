import json
import os
from pathlib import Path
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

BASE_DIR = Path(__file__).parent
DATASET_DIR = BASE_DIR / "dataset_test"
LOG_PATH = BASE_DIR / "logs" / "relaciones.json"

model = SentenceTransformer("hiiamsid/sentence_similarity_spanish_es")
memorias = []

# Cargar memorias
for file in DATASET_DIR.glob("*.json"):
    with open(file, 'r', encoding='utf-8') as f:
        data = json.load(f)
        if 'contenido' in data and 'id' in data:
            memorias.append(data)

if not memorias:
    print("No se encontraron memorias vÃ¡lidas.")
    exit()

# Generar embeddings
textos = [m["contenido"] for m in memorias]
embeddings = model.encode(textos)

# Calcular similitudes
relaciones = []
sim_matrix = cosine_similarity(embeddings)
n = len(memorias)

for i in range(n):
    for j in range(i+1, n):
        sim = float(sim_matrix[i][j])
        if sim > 0.7:
            relaciones.append({
                "memoria_1": memorias[i]["id"],
                "memoria_2": memorias[j]["id"],
                "score": round(sim, 3)
            })

# Guardar
with open(LOG_PATH, 'w', encoding='utf-8') as f:
    json.dump(relaciones, f, indent=2, ensure_ascii=False)

print(f"Proceso completo. Relaciones guardadas en {LOG_PATH}")