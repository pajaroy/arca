#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ALMA_RESIST - Bit√°cora Institucional v0.4.0
Sistema CLI antifallos con almacenamiento Parquet y gobernanza documental
"""
import os
import sys
import json
import uuid
import argparse
import hashlib
import logging
import shutil
import glob
import re
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
import yaml
import pandas as pd
import pyarrow.parquet as pq
from logging.handlers import RotatingFileHandler

# --- CONFIGURACI√ìN GLOBAL ---
DEFAULT_PARQUET_PATH = "/home/alma/Documents/Journal/Bitacora/bitacora_viva.parquet"
DEFAULT_METADATA_PATH = "/home/alma/Documents/Journal/Bitacora/bitacora_viva.metadata.yaml"
BACKUP_DIR = "/home/alma/Documents/Journal/Bitacora/backups"
LOG_DIR = "/home/alma/Logs"
RETENCION_BACKUPS = 30  # D√≠as de retenci√≥n por defecto
VALID_ESTADOS = ["registrado", "en_progreso", "completado", "cancelado", "revisi√≥n"]
METADATA_FIELDS = [
    "version", "tipo", "schema", "descripcion", "estructura", "tags", 
    "linked_to", "responsable", "hash_parquet", "hash_metadata",
    "historial", "last_modified", "last_modified_by"
]
CONFIG_FILE = "bitacora_config.yaml"
SCHEMA_VERSION = "0.4.0"

# --- CLASES PRINCIPALES ---
class ParquetManager:
    """Maneja operaciones con archivos Parquet"""
    @staticmethod
    def read_parquet(path: Path) -> pd.DataFrame:
        """Lee un archivo Parquet con validaci√≥n de esquema"""
        if not path.exists():
            # Crea DataFrame vac√≠o con dtypes correctos
            return pd.DataFrame({
                'id': pd.Series(dtype='object'),
                'fecha': pd.Series(dtype='datetime64[ns, UTC]'),
                'accion': pd.Series(dtype='object'),
                'descripcion': pd.Series(dtype='object'),
                'motivo': pd.Series(dtype='object'),
                'ejecutado_por': pd.Series(dtype='object'),
                'estado': pd.Series(dtype='object'),
                'tags': pd.Series(dtype='object')
            })

        try:
            df = pd.read_parquet(path)

            # Forzar conversi√≥n de fecha si est√° como string
            if 'fecha' in df.columns and df['fecha'].dtype == 'object':
                df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')

            return df
        except Exception as e:
            raise RuntimeError(f"Error leyendo Parquet: {str(e)}")


    @staticmethod
    def write_parquet(df: pd.DataFrame, path: Path):
        """Escribe un DataFrame a Parquet con compresi√≥n √≥ptima"""
        try:
            df.to_parquet(
                path, 
                compression='snappy',
                index=False,
                allow_truncated_timestamps=True
            )
        except Exception as e:
            raise RuntimeError(f"Error escribiendo Parquet: {str(e)}")

    @staticmethod
    def validate_schema(df: pd.DataFrame):
        """Valida que el DataFrame tenga el esquema correcto"""
        required_columns = {
            'id': 'object',
            'fecha': 'datetime64[ns, UTC]',
            'accion': 'object',
            'descripcion': 'object',
            'motivo': 'object',
            'ejecutado_por': 'object',
            'estado': 'object',
            'tags': 'object'
        }
        
        for col, dtype in required_columns.items():
            if col not in df.columns:
                raise ValueError(f"Columna faltante: {col}")
            if df[col].dtype != dtype:
                raise TypeError(f"Tipo inv√°lido para {col}. Esperado: {dtype}, Actual: {df[col].dtype}")


class BitacoraManager:
    def __init__(self, args):
        self.args = args
        self.parquet_path = Path(args.parquet).absolute()
        self.metadata_path = Path(args.metadata).absolute()
        self.config = self.cargar_configuracion()
        self.logger = self.configurar_logging()
        self.entradas_df = None
        self.metadata = None
        self.backup_realizado = False

    def cargar_configuracion(self) -> dict:
        """Carga configuraci√≥n con valores por defecto"""
        config_path = Path(CONFIG_FILE)
        config = {
            "retencion_backups": RETENCION_BACKUPS,
            "max_backups": 100,
            "log_rotacion": "10MB",
            "log_copias": 5
        }
        
        if config_path.exists():
            try:
                with open(config_path, 'r') as f:
                    user_config = yaml.safe_load(f) or {}
                config.update(user_config)
            except Exception as e:
                print(f"‚ö†Ô∏è Error cargando configuraci√≥n: {str(e)}")
        
        return config

    def configurar_logging(self):
        """Configura logging avanzado con rotaci√≥n"""
        logger = logging.getLogger('bitacora_antifallos')
        logger.setLevel(logging.DEBUG if self.args.verbose else logging.INFO)
        
        # Formato est√°ndar ALMA_RESIST
        formato = logging.Formatter(
            '%(asctime)s | %(levelname)s | %(module)s | %(message)s',
            datefmt='%Y-%m-%dT%H:%M:%SZ'
        )
        formato.converter = lambda *args: datetime.now(timezone.utc).timetuple()
        
        # Handler de consola
        consola = logging.StreamHandler()
        consola.setFormatter(formato)
        logger.addHandler(consola)
        
        # Handler de archivo rotativo
        if self.args.log:
            Path(LOG_DIR).mkdir(parents=True, exist_ok=True)
            log_file = Path(LOG_DIR) / f"bitacora_{datetime.now(timezone.utc).strftime('%Y%m')}.log"
            rotacion = RotatingFileHandler(
                log_file,
                maxBytes=self._parse_log_size(self.config['log_rotacion']),
                backupCount=self.config['log_copias']
            )
            rotacion.setFormatter(formato)
            logger.addHandler(rotacion)
        
        return logger

    def _parse_log_size(self, size_str: str) -> int:
        """Convierte tama√±o de log en bytes"""
        unidades = {"KB": 1024, "MB": 1024**2, "GB": 1024**3}
        match = re.match(r"(\d+)\s*([KMG]B)", size_str.upper())
        if match:
            valor, unidad = match.groups()
            return int(valor) * unidades[unidad]
        return 10 * 1024**2  # 10MB por defecto

    def validar_entrada(self, entrada: dict):
        """Validaci√≥n estricta de estructura y tipos de datos"""
        campos_obligatorios = {
            "fecha": str,
            "accion": str,
            "descripcion": str,
            "motivo": str,
            "ejecutado_por": str
        }
        
        # Verificar campos obligatorios
        for campo, tipo in campos_obligatorios.items():
            if campo not in entrada:
                raise ValueError(f"Campo obligatorio faltante: {campo}")
            if not isinstance(entrada[campo], tipo):
                raise TypeError(f"Tipo inv√°lido para {campo}. Esperado: {tipo.__name__}")
        
        # Validar estado
        if entrada.get("estado") and entrada["estado"] not in VALID_ESTADOS:
            raise ValueError(f"Estado inv√°lido: {entrada['estado']}. Validos: {', '.join(VALID_ESTADOS)}")
        
        # Validar tags
        if "tags" in entrada and not isinstance(entrada["tags"], list):
            raise TypeError("Tags debe ser una lista")
        
        # Validar formato fecha ISO
        try:
            datetime.fromisoformat(entrada["fecha"])
        except ValueError:
            raise ValueError("Formato de fecha inv√°lido. Debe ser ISO 8601")

    def validar_metadata(self, metadata: dict):
        """Validaci√≥n completa de metadatos"""
        for campo in METADATA_FIELDS:
            if campo not in metadata:
                raise ValueError(f"Metadato obligatorio faltante: {campo}")
        
        # Validar historial de cambios
        if not isinstance(metadata["historial"], list):
            raise TypeError("El historial debe ser una lista de registros")
        
        # Validar hashes
        for hash_field in ["hash_parquet", "hash_metadata"]:
            if metadata[hash_field] and not metadata[hash_field].startswith("sha256:"):
                raise ValueError(f"Formato de hash inv√°lido para {hash_field}. Debe ser 'sha256:<hash>'")

    def cargar_metadata(self) -> dict:
        """Carga los metadatos con validaci√≥n"""
        if not self.metadata_path.exists():
            return self.crear_metadata_vacia()
        
        try:
            with open(self.metadata_path, 'r') as f:
                metadata = yaml.safe_load(f)
            
            self.validar_metadata(metadata)
            return metadata
        except (yaml.YAMLError, ValueError, TypeError) as e:
            self.logger.error(f"ERROR METADATA: {str(e)}")
            raise RuntimeError(f"Metadata corrupto: {str(e)}")

    def crear_metadata_vacia(self) -> dict:
        """Crea estructura inicial de metadatos"""
        return {
            "version": SCHEMA_VERSION,
            "tipo": "bitacora",
            "schema": "almaresist.bitacora_v1",
            "descripcion": "Bit√°cora institucional de ALMA_RESIST",
            "estructura": "parquet + metadata",
            "tags": ["bitacora", "institucional"],
            "linked_to": [],
            "responsable": "Equipo de Operaciones",
            "hash_parquet": "",
            "hash_metadata": "",
            "historial": [],
            "last_modified": datetime.now(timezone.utc).isoformat(),
            "last_modified_by": "system"
        }

    def cargar_entradas(self) -> pd.DataFrame:
        """Carga las entradas desde Parquet con validaci√≥n de esquema"""
        try:
            df = ParquetManager.read_parquet(self.parquet_path)
            
            # Convertir tags a lista si es necesario
            import numpy as np

            if 'tags' in df.columns and df['tags'].dtype == 'object':
                def normalize_tags(x):
                    if isinstance(x, list):
                        return x
                    if isinstance(x, np.ndarray):
                        return x.tolist()
                    if pd.isna(x):
                        return []
                    return [x]
    
                df['tags'] = df['tags'].apply(normalize_tags)

            
            # Validar esquema
            ParquetManager.validate_schema(df)
            return df
        except Exception as e:
            self.logger.error(f"ERROR PARQUET: {str(e)}")
            raise RuntimeError(f"Error cargando entradas: {str(e)}")

    def crear_backup(self) -> Tuple[Path, Path]:
        """Crea backup de ambos archivos con pol√≠tica de retenci√≥n"""
        backup_dir = Path(BACKUP_DIR).absolute()
        backup_dir.mkdir(parents=True, exist_ok=True)

        # Crear Parquet vac√≠o si no existe
        if not self.parquet_path.exists():
            empty_df = pd.DataFrame({
                'id': pd.Series(dtype='object'),
                'fecha': pd.Series(dtype='datetime64[ns]'),
                'accion': pd.Series(dtype='object'),
                'descripcion': pd.Series(dtype='object'),
                'motivo': pd.Series(dtype='object'),
                'ejecutado_por': pd.Series(dtype='object'),
                'estado': pd.Series(dtype='object'),
                'tags': pd.Series(dtype='object')
            })
            ParquetManager.write_parquet(empty_df, self.parquet_path)
            self.logger.info(f"Archivo Parquet creado vac√≠o: {self.parquet_path}")

        # Crear Metadata vac√≠o si no existe
        if not self.metadata_path.exists():
            with open(self.metadata_path, 'w') as f:
                yaml.dump(self.crear_metadata_vacia(), f, sort_keys=False, allow_unicode=True)
            self.logger.info(f"Metadata YAML creado vac√≠o: {self.metadata_path}")


        
        # Crear backup con timestamp
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        parquet_backup = backup_dir / f"bitacora_backup_{timestamp}.parquet"
        metadata_backup = backup_dir / f"metadata_backup_{timestamp}.yaml"
        
        try:
            # Copiar archivos
            shutil.copy2(self.parquet_path, parquet_backup)
            shutil.copy2(self.metadata_path, metadata_backup)
            self.logger.info(f"Backups creados: {parquet_backup.name}, {metadata_backup.name}")
            
            # Aplicar pol√≠tica de retenci√≥n
            self.aplicar_retencion_backups(backup_dir)
            
            self.backup_realizado = True
            return parquet_backup, metadata_backup
        except Exception as e:
            self.logger.error(f"FALLO EN BACKUP: {str(e)}")
            raise RuntimeError(f"Error creando backup: {str(e)}")

    def aplicar_retencion_backups(self, backup_dir: Path):
        parquet_backups = sorted(backup_dir.glob("bitacora_backup_*.parquet"), key=os.path.getmtime)
        metadata_backups = sorted(backup_dir.glob("metadata_backup_*.yaml"), key=os.path.getmtime)

        all_backups = set(b.name.split('_')[2] for b in parquet_backups + metadata_backups)

        limite_tiempo = datetime.now(timezone.utc) - timedelta(days=self.config['retencion_backups'])

        for ts in all_backups:
            try:
                # ‚úÖ Intentar parsear el timestamp
                try:
                    backup_time = datetime.strptime(ts, "%Y%m%d_%H%M%S").replace(tzinfo=timezone.utc)
                except ValueError:
                    self.logger.warning(f"Timestamp de backup ignorado por formato inv√°lido: {ts}")
                    continue

                if backup_time < limite_tiempo:
                    for ext in ['.parquet', '.yaml']:
                        backup_file = backup_dir / f"bitacora_backup_{ts}{ext}"
                        if backup_file.exists():
                            backup_file.unlink()
                            self.logger.info(f"Backup eliminado (retenci√≥n): {backup_file.name}")

            except Exception as e:
                self.logger.error(f"Error eliminando backup: {str(e)}")

        # Control por cantidad m√°xima
        if len(all_backups) > self.config['max_backups']:
            backups_to_keep = sorted(all_backups, reverse=True)[:self.config['max_backups']]
            for ts in set(all_backups) - set(backups_to_keep):
                for ext in ['.parquet', '.yaml']:
                    backup_file = backup_dir / f"bitacora_backup_{ts}{ext}"
                    if backup_file.exists():
                        try:
                            backup_file.unlink()
                            self.logger.info(f"Backup eliminado (cantidad): {backup_file.name}")
                        except Exception as e:
                            self.logger.error(f"Error eliminando backup: {str(e)}")

    def calcular_hash_archivo(self, file_path: Path) -> str:
        """Calcula hash SHA-256 institucional"""
        sha256 = hashlib.sha256()
        try:
            with open(file_path, 'rb') as f:
                while chunk := f.read(4096):
                    sha256.update(chunk)
            return f"sha256:{sha256.hexdigest()}"
        except Exception as e:
            self.logger.error(f"ERROR DE HASH: {str(e)}")
            raise RuntimeError(f"Error calculando hash: {str(e)}")

    def calcular_hash_metadata(self, metadata_path: Path) -> str:
        """
        Calcula hash SHA-256 del metadata YAML
        ignorando el campo hash_metadata para evitar bucles.
        """
        with open(metadata_path, 'r') as f:
            metadata = yaml.safe_load(f)

        if "hash_metadata" in metadata:
            metadata.pop("hash_metadata")

        # Serializar nuevamente para asegurar orden consistente
        serialized = yaml.dump(
            metadata, sort_keys=True, allow_unicode=True
        )
        sha256 = hashlib.sha256(serialized.encode("utf-8")).hexdigest()
        return f"sha256:{sha256}"


    def registrar_cambio(self, accion: str, entrada_id: str = None):
        """Registra en changelog con trazabilidad completa"""
        if not self.metadata:
            return
            
        # Guardar hashes previos para auditor√≠a
        hash_previo_parquet = self.metadata.get("hash_parquet", "")
        hash_previo_metadata = self.metadata.get("hash_metadata", "")
        
        nuevo_registro = {
            "fecha": datetime.now(timezone.utc).isoformat(),
            "accion": accion,
            "ejecutado_por": self.args.ejecutado_por,
            "hash_previo_parquet": hash_previo_parquet,
            "hash_previo_metadata": hash_previo_metadata,
            "entrada_id": entrada_id
        }
        self.metadata["historial"].append(nuevo_registro)
        self.metadata["last_modified"] = nuevo_registro["fecha"]
        self.metadata["last_modified_by"] = nuevo_registro["ejecutado_por"]
        
        self.logger.info(f"Registro changelog: {accion} | Entrada: {entrada_id or 'N/A'}")

    def guardar_todo(self):
        """Guarda ambos archivos y actualiza hashes"""
        try:
            # Guardar entradas Parquet
            ParquetManager.write_parquet(self.entradas_df, self.parquet_path)

            # Actualizar hash Parquet
            self.metadata["hash_parquet"] = self.calcular_hash_archivo(self.parquet_path)

            # Guardar metadata sin hash_metadata
            metadata_copy = self.metadata.copy()
            metadata_copy.pop("hash_metadata", None)

            with open(self.metadata_path, 'w') as f:
                yaml.dump(metadata_copy, f, sort_keys=True, allow_unicode=True)

            # Calcular nuevo hash del metadata
            self.metadata["hash_metadata"] = self.calcular_hash_metadata(self.metadata_path)

            # Ahora volver a guardarlo incluyendo el hash
            metadata_with_hash = self.metadata.copy()
            with open(self.metadata_path, 'w') as f:
                yaml.dump(metadata_with_hash, f, sort_keys=True, allow_unicode=True)

            self.logger.info("Bit√°cora actualizada con √©xito")
            return True

        except Exception as e:
            self.logger.error(f"FALLO GUARDADO: {str(e)}")
            if self.backup_realizado:
                self.logger.warning("‚ö†Ô∏è  Restaurando desde √∫ltimo backup...")
                self.restaurar_backup()
            raise RuntimeError(f"Error guardando bit√°cora: {str(e)}")

    def generar_documentacion(self):
        """Genera documentos secundarios (JSON y Markdown)"""
        try:
            # Crear directorios si no existen
            docs_dir = self.parquet_path.parent / "documentacion"
            docs_dir.mkdir(exist_ok=True)
            
            # Generar JSON combinado
            combined_data = {
                "metadata": self.metadata,
                "entradas": self.entradas_df.to_dict(orient='records')
            }
            json_path = docs_dir / "bitacora_completa.json"
            with open(json_path, 'w') as f:
                json.dump(combined_data, f, indent=2, ensure_ascii=False, default=str)
            
            # Generar Markdown
            md_path = docs_dir / "bitacora_resumen.md"
            self.generar_markdown(md_path)
            
            self.logger.info(f"Documentaci√≥n generada en: {docs_dir}")
            return True
        except Exception as e:
            self.logger.error(f"ERROR GENERANDO DOCS: {str(e)}")
            return False

    def generar_markdown(self, md_path: Path):
        """Genera documento Markdown con front matter"""
        with open(md_path, 'w') as f:
            # Front matter
            f.write("---\n")
            yaml.dump(self.metadata, f, sort_keys=False, allow_unicode=True)
            f.write("---\n\n")
            
            # Cuerpo
            f.write(f"# Bit√°cora Institucional: {self.metadata['descripcion']}\n\n")
            f.write(f"**√öltima modificaci√≥n**: {self.metadata['last_modified']} ")
            f.write(f"por *{self.metadata['last_modified_by']}*\n\n")
            f.write(f"**Hash Parquet**: `{self.metadata['hash_parquet']}`\n")
            f.write(f"**Hash Metadata**: `{self.metadata['hash_metadata']}`\n\n")
            f.write("---\n\n")
            
            # Entradas
            for _, row in self.entradas_df.iterrows():
                f.write(f"## {row['accion']} ({row['fecha']})\n")
                f.write(f"**ID**: `{row.get('id', '')}`  \n")
                f.write(f"**Ejecutado por**: {row['ejecutado_por']}  \n")
                f.write(f"**Estado**: {row.get('estado', 'registrado')}  \n")
                f.write(f"**Motivo**: {row['motivo']}\n\n")
                f.write(f"### Descripci√≥n\n{row['descripcion']}\n\n")
                if row.get('tags') is not None and len(row.get('tags')) > 0:
                    f.write(f"**Tags**: `{', '.join(row['tags'])}`\n\n")
                f.write("---\n\n")

    def agregar_entrada(self, entrada: dict, confirmar: bool = True):
        try:
            # Validaci√≥n preliminar
            self.validar_entrada(entrada)

            # Cargar datos
            self.metadata = self.cargar_metadata()
            self.entradas_df = self.cargar_entradas()

            # Vista previa
            if self.args.preview or confirmar:
                self.mostrar_previa(entrada)
                if confirmar and not self.confirmar_accion("¬øAgregar entrada?"):
                    self.logger.info("Operaci√≥n cancelada por el usuario")
                    return False

            if not self.args.dry_run:
                self.crear_backup()
                entrada["id"] = str(uuid.uuid4())

                # ‚úÖ FIX #3 ‚Üí convertir fecha a timestamp
                if isinstance(entrada["fecha"], str):
                    entrada["fecha"] = pd.to_datetime(entrada["fecha"], utc=True)

                new_row = pd.DataFrame([entrada])

                # Garantizar tipos correctos
                for col in new_row.columns:
                    if col in self.entradas_df.columns:
                        new_row[col] = new_row[col].astype(self.entradas_df[col].dtype)

                self.entradas_df = pd.concat([self.entradas_df, new_row], ignore_index=True)

                self.guardar_todo()
                self.registrar_cambio("alta", entrada["id"])

                self.logger.info(f"‚úÖ Entrada agregada: ID={entrada['id']}")
                return True
            else:
                self.logger.info("‚úÖ Simulaci√≥n completada (dry-run)")
                return True

        except Exception as e:
            self.logger.error(f"üö® ERROR CR√çTICO: {str(e)}")
            if self.backup_realizado:
                self.logger.warning("Revertiendo cambios...")
                self.restaurar_backup()
            return False


    def mostrar_previa(self, entrada: dict):
        """Muestra vista previa de la entrada"""
        print("\n--- VISTA PREVIA DE ENTRADA ---")
        print(f"Acci√≥n: {entrada['accion']}")
        print(f"Descripci√≥n: {entrada['descripcion'][:100]}...")
        print(f"Motivo: {entrada['motivo']}")
        print(f"Ejecutado por: {entrada['ejecutado_por']}")
        print(f"Estado: {entrada.get('estado', 'registrado')}")
        tags = entrada.get('tags')
        if tags is not None and len(tags) > 0:
            print(f"Tags: {', '.join(tags)}")
        else:
            print("Tags: -")

        print("-------------------------------\n")

    def confirmar_accion(self, mensaje: str) -> bool:
        """Confirmaci√≥n interactiva con el usuario"""
        if self.args.yes:
            return True
        respuesta = input(f"{mensaje} [s/N] ").strip().lower()
        return respuesta in ['s', 'y', 'si', 'yes']

    def restaurar_backup(self, backup_timestamp: str = None):
        """Restaura desde un backup espec√≠fico"""
        backup_dir = Path(BACKUP_DIR)
        
        if not backup_timestamp:
            # Encontrar el backup m√°s reciente
            backups = sorted(
                [f.name.split('_')[2] for f in backup_dir.glob("bitacora_backup_*.parquet")],
                reverse=True
            )
            if not backups:
                self.logger.error("No hay backups disponibles")
                return False
            backup_timestamp = backups[0]
        
        parquet_backup = backup_dir / f"bitacora_backup_{backup_timestamp}.parquet"
        metadata_backup = backup_dir / f"metadata_backup_{backup_timestamp}.yaml"
        
        if not parquet_backup.exists() or not metadata_backup.exists():
            self.logger.error(f"Backup incompleto para timestamp: {backup_timestamp}")
            return False
        
        try:
            # Restaurar archivos
            shutil.copy2(parquet_backup, self.parquet_path)
            shutil.copy2(metadata_backup, self.metadata_path)
            self.logger.info(f"‚úÖ Bit√°cora restaurada desde backup: {backup_timestamp}")
            return True
        except Exception as e:
            self.logger.error(f"FALLO RESTAURACI√ìN: {str(e)}")
            return False

    def validar_bitacora(self) -> bool:
        try:
            metadata = self.cargar_metadata()

            # Verificar hash metadata
            metadata_hash = self.calcular_hash_metadata(self.metadata_path)
            if metadata_hash != metadata["hash_metadata"]:
                raise ValueError(f"Hash metadata no coincide. Calculado: {metadata_hash}")

            # Verificar hash Parquet
            parquet_hash = self.calcular_hash_archivo(self.parquet_path)
            if parquet_hash != metadata["hash_parquet"]:
                raise ValueError(f"Hash Parquet no coincide. Calculado: {parquet_hash}")

            df = self.cargar_entradas()

            self.logger.info("‚úÖ Validaci√≥n exitosa. Integridad confirmada.")
            return True

        except Exception as e:
            self.logger.error(f"üö® VALIDACI√ìN FALLIDA: {str(e)}")
            return False


# --- COMANDOS CLI ---
def comando_agregar(args, manager: BitacoraManager):
    """Maneja el comando de agregar entrada"""
    entrada = {
        "fecha": datetime.now(timezone.utc).isoformat(),
        "accion": args.accion,
        "descripcion": args.descripcion,
        "motivo": args.motivo,
        "ejecutado_por": args.ejecutado_por,
        "estado": args.estado,
        "tags": args.tags.split(",") if args.tags else []
    }
    return manager.agregar_entrada(entrada, not args.yes)

def comando_validar(args, manager: BitacoraManager):
    """Valida integridad de la bit√°cora"""
    return manager.validar_bitacora()

def comando_restaurar(args, manager: BitacoraManager):
    """Restaura desde un backup"""
    if args.list:
        backups = sorted(
            [f.name.split('_')[2] for f in Path(BACKUP_DIR).glob("bitacora_backup_*.parquet")],
            reverse=True
        )
        print("\nBackups disponibles:")
        for i, ts in enumerate(backups[:5]):
            print(f"[{i+1}] {ts}")
        return True
    
    return manager.restaurar_backup(args.backup_timestamp)

def comando_generar_docs(args, manager: BitacoraManager):
    """Genera documentaci√≥n t√©cnica autom√°tica"""
    try:
        manager.metadata = manager.cargar_metadata()
        manager.entradas_df = manager.cargar_entradas()
        return manager.generar_documentacion()
    except Exception as e:
        manager.logger.error(f"ERROR GENERANDO DOCS: {str(e)}")
        return False

# --- FUNCI√ìN PRINCIPAL ---
def main():
    parser = argparse.ArgumentParser(
        description="ALMA_RESIST - Sistema de Bit√°coras Institucionales v0.4.0",
        epilog="Ejemplo completo:\n  python add_bitacora_entry_v0.4.0.py agregar \\\n"
               "    --accion 'Actualizaci√≥n de seguridad' \\\n"
               "    --descripcion 'Parche contra vulnerabilidad CVE-2023-1234' \\\n"
               "    --motivo 'Protecci√≥n de sistemas cr√≠ticos' \\\n"
               "    --ejecutado_por 'admin@dominio.com' \\\n"
               "    --tags 'seguridad,parche,urgente' \\\n"
               "    --preview --log",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    # Argumentos globales
    parser.add_argument("--parquet", default=DEFAULT_PARQUET_PATH, 
                       help="Ruta al archivo Parquet de entradas")
    parser.add_argument("--metadata", default=DEFAULT_METADATA_PATH, 
                       help="Ruta al archivo de metadatos")
    parser.add_argument("--verbose", action="store_true", 
                       help="Salida detallada del proceso")
    parser.add_argument("--log", action="store_true", 
                       help="Registrar en archivo de log")
    parser.add_argument("--yes", "-y", action="store_true",
                       help="Confirmar autom√°ticamente todas las acciones")
    
    subparsers = parser.add_subparsers(dest='comando', required=True, title="Comandos")
    
    # Comando: agregar
    parser_agregar = subparsers.add_parser('agregar', help='Agregar nueva entrada')
    parser_agregar.add_argument("--accion", required=True, help="Acci√≥n realizada")
    parser_agregar.add_argument("--descripcion", required=True, help="Descripci√≥n detallada")
    parser_agregar.add_argument("--motivo", required=True, help="Motivo de la acci√≥n")
    parser_agregar.add_argument("--ejecutado_por", required=True, help="Responsable de la acci√≥n")
    parser_agregar.add_argument("--estado", default="registrado", choices=VALID_ESTADOS,
                               help="Estado actual de la acci√≥n")
    parser_agregar.add_argument("--tags", help="Etiquetas asociadas (separadas por comas)")
    parser_agregar.add_argument("--dry-run", action="store_true", 
                               help="Simular sin realizar cambios")
    parser_agregar.add_argument("--preview", action="store_true",
                               help="Mostrar vista previa antes de guardar")
    
    # Comando: validar
    parser_validar = subparsers.add_parser('validar', help='Validar integridad de la bit√°cora')
    
    # Comando: restaurar
    parser_restaurar = subparsers.add_parser('restaurar', help='Restaurar desde backup')
    parser_restaurar.add_argument("--backup-timestamp", help="Timestamp espec√≠fico del backup (ej: 20230715_143022)")
    parser_restaurar.add_argument("--list", action="store_true", help="Listar backups disponibles")
    
    # Comando: generar-docs
    parser_docs = subparsers.add_parser('generar-docs', help='Generar documentaci√≥n t√©cnica')
    
    args = parser.parse_args()
    
    try:
        manager = BitacoraManager(args)
        manager.logger.info(f"üöÄ Iniciando comando: {args.comando.upper()}")
        
        if args.comando == "agregar":
            resultado = comando_agregar(args, manager)
        elif args.comando == "validar":
            resultado = comando_validar(args, manager)
        elif args.comando == "restaurar":
            resultado = comando_restaurar(args, manager)
        elif args.comando == "generar-docs":
            resultado = comando_generar_docs(args, manager)
        else:
            parser.print_help()
            resultado = False
        
        sys.exit(0 if resultado else 1)
    except Exception as e:
        logging.error(f"FALLO SIST√âMICO: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()