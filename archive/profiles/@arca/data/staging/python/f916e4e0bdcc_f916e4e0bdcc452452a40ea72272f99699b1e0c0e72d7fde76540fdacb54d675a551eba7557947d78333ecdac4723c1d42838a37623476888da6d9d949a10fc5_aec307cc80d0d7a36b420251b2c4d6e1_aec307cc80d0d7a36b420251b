#!/usr/bin/env python3
"""
Script CLI para carga y sincronizaci√≥n de memorias institucionales (v0.1.1)
Autor: Kael & Santi
Fecha: 2025-06-08
Mejoras:
  - Correcci√≥n serializaci√≥n JSON con fechas
  - Validaci√≥n y normalizaci√≥n de formato fecha (ISO)
  - Mejoras en logging y auditor√≠a CLI
"""
import argparse
import os
import sys
import json
import yaml
import logging
from datetime import datetime, date
from collections import OrderedDict
import shutil

# Configuraci√≥n avanzada de logging
logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')
logger = logging.getLogger('ALMA_RESIST_MEMCLI')

# Estructura m√≠nima requerida para memorias
CAMPOS_REQUERIDOS = ['id', 'fecha', 'tipo', 'autor', 'contenido']

def validar_estructura(memoria):
    """Valida estructura m√≠nima y formato de campos"""
    # Verificar campos requeridos
    faltantes = [campo for campo in CAMPOS_REQUERIDOS if campo not in memoria]
    if faltantes:
        logger.error(f"Campos faltantes: {', '.join(faltantes)}")
        return False
    
    # Validaci√≥n especial para fecha
    fecha_val = memoria['fecha']
    if isinstance(fecha_val, date):
        memoria['fecha'] = fecha_val.isoformat()  # Normalizar a ISO
    elif isinstance(fecha_val, str):
        try:
            # Verificar formato ISO b√°sico
            datetime.strptime(fecha_val, "%Y-%m-%d")
        except ValueError:
            logger.error(f"Formato fecha inv√°lido: {fecha_val} (requerido YYYY-MM-DD)")
            return False
    else:
        logger.error(f"Tipo de fecha no soportado: {type(fecha_val)}")
        return False
    
    return True

def cargar_archivo(ruta):
    """Carga y parsea archivos YAML o Markdown con frontmatter"""
    try:
        with open(ruta, 'r', encoding='utf-8') as f:
            contenido = f.read()
            
        if not contenido.strip():
            logger.warning(f"Archivo vac√≠o: {ruta}")
            return []
            
        if ruta.endswith('.yaml') or ruta.endswith('.yml'):
            return yaml.safe_load(contenido) or []
        
        elif ruta.endswith('.md'):
            if not contenido.startswith('---\n'):
                raise ValueError("Formato Markdown inv√°lido: falta frontmatter")
            partes = contenido.split('---\n', 2)
            if len(partes) < 3:
                raise ValueError("Formato Markdown inv√°lido: delimitadores insuficientes")
            
            frontmatter = yaml.safe_load(partes[1])
            frontmatter['contenido'] = partes[2].strip()
            return [frontmatter]
        
        else:
            raise ValueError("Formato de archivo no soportado")
    
    except Exception as e:
        logger.error(f"Error procesando {ruta}: {str(e)}")
        return []

def crear_backup(archivo, directorio=None):
    """Crea backup con timestamp del archivo original"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nombre_backup = f"{os.path.basename(archivo)}.backup_{timestamp}"
        destino = os.path.join(directorio or os.path.dirname(archivo), nombre_backup)
        
        shutil.copy2(archivo, destino)
        logger.info(f"Backup creado: {destino}")
        return True
    
    except Exception as e:
        logger.error(f"Error en backup de {archivo}: {str(e)}")
        return False

def sincronizar_memorias(args):
    """L√≥gica principal de carga y sincronizaci√≥n"""
    # Cargar y normalizar memorias existentes
    memorias_existentes = cargar_archivo(args.memoria_yaml) or []
    mapa_existentes = {m['id']: m for m in memorias_existentes}
    
    # Cargar nuevas memorias
    nuevas_memorias = cargar_archivo(args.entrada)
    if isinstance(nuevas_memorias, dict):  # caso de una sola memoria
        nuevas_memorias = [nuevas_memorias]
    if not nuevas_memorias:
        logger.error("No se encontraron memorias v√°lidas en el archivo de entrada")
        return False
    
    # Contadores detallados
    procesadas = []
    duplicados = []
    invalidas = []
    errores_fecha = []
    
    for memoria in nuevas_memorias:
        mem_id = memoria.get('id', 'SIN_ID')
        
        # Validaci√≥n en dos fases
        if not validar_estructura(memoria):
            invalidas.append(mem_id)
            continue
            
        # Detectar duplicados
        if memoria['id'] in mapa_existentes:
            if args.modo == 'replace':
                procesadas.append(('REEMPLAZADA', memoria))
            else:
                duplicados.append(memoria['id'])
        else:
            procesadas.append(('AGREGADA', memoria))
    
    # Modo dry-run: mostrar simulaci√≥n detallada
    if args.dry_run:
        logger.info("\n" + "="*60)
        logger.info("üìã RESULTADO SIMULACI√ìN (dry-run)")
        logger.info("="*60)
        for accion, memoria in procesadas:
            logger.info(f"[{accion}] {memoria['id']}: {memoria['tipo']} por {memoria['autor']}")
        
        if duplicados:
            logger.info("\nüö´ DUPLICADOS DETECTADOS (no procesados):")
            logger.info("\n".join(f" - {d}" for d in duplicados))
        
        if invalidas:
            logger.info(f"\n‚ùå ENTRADAS INV√ÅLIDAS: {len(invalidas)}")
            logger.info("IDs: " + ", ".join(invalidas))
        
        logger.info("\nüíæ Resumen:")
        logger.info(f" - Nuevas: {len([a for a, _ in procesadas if a == 'AGREGADA'])}")
        logger.info(f" - Actualizaciones: {len([a for a, _ in procesadas if a == 'REEMPLAZADA'])}")
        logger.info(f" - Duplicados: {len(duplicados)}")
        logger.info(f" - Inv√°lidas: {len(invalidas)}")
        return True
    
    # Crear backups antes de modificar
    crear_backup(args.memoria_yaml, args.backup_dir)
    crear_backup(args.memoria_json, args.backup_dir)
    
    # Aplicar cambios
    for accion, memoria in procesadas:
        if accion == 'REEMPLAZADA':
            # Actualizar entrada existente
            for i, existente in enumerate(memorias_existentes):
                if existente['id'] == memoria['id']:
                    memorias_existentes[i] = memoria
                    break
        else:
            # Agregar nueva entrada
            memorias_existentes.append(memoria)
    
    # Guardar archivos actualizados con serializaci√≥n segura
    try:
        with open(args.memoria_yaml, 'w', encoding='utf-8') as f:
            yaml.dump(memorias_existentes, f, allow_unicode=True, sort_keys=False)
        
        with open(args.memoria_json, 'w', encoding='utf-8') as f:
            json.dump(memorias_existentes, f, indent=2, ensure_ascii=False, default=str)
        
        # Reporte final de operaci√≥n
        logger.info("\n" + "="*60)
        logger.info("‚úÖ RESULTADO DE CARGA")
        logger.info("="*60)
        logger.info(f"üì¶ Memorias procesadas: {len(procesadas)}")
        logger.info(f"  ‚î£ Nuevas: {len([a for a, _ in procesadas if a == 'AGREGADA'])}")
        logger.info(f"  ‚îó Actualizadas: {len([a for a, _ in procesadas if a == 'REEMPLAZADA'])}")
        logger.info(f"üö´ Duplicados omitidos: {len(duplicados)}")
        logger.info(f"‚ùå Entradas inv√°lidas: {len(invalidas)}")
        
        if invalidas:
            logger.info("\nüîç IDs inv√°lidos detectados:")
            logger.info(", ".join(invalidas))
        
        return True
    
    except Exception as e:
        logger.error(f"‚õî Error guardando cambios: {str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description="Carga y sincronizaci√≥n de memorias institucionales ALMA_RESIST v0.1.1",
        epilog="Filosof√≠a: Trazabilidad total | Auditor√≠a CLI | Sincronizaci√≥n bidireccional",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # Argumentos requeridos
    parser.add_argument('--entrada', required=True, help='Ruta al archivo con nuevas memorias')
    parser.add_argument('--memoria-yaml', required=True, help='Ruta al archivo YAML oficial')
    parser.add_argument('--memoria-json', required=True, help='Ruta al archivo JSON oficial')
    
    # Opciones de funcionamiento
    parser.add_argument('--modo', choices=['append', 'replace'], default='append',
                        help='Modo de integraci√≥n: append (agrega) o replace (sobrescribe)')
    parser.add_argument('--backup-dir', help='Directorio personalizado para backups')
    
    # Flags de control
    parser.add_argument('--dry-run', action='store_true', help='Simula operaci√≥n sin guardar cambios')
    parser.add_argument('--verbose', action='store_true', help='Muestra detalles de ejecuci√≥n')
    parser.add_argument('--debug', action='store_true', help='Modo diagn√≥stico con salida extendida')
    
    args = parser.parse_args()
    
    # Configurar verbosidad
    if args.debug:
        logger.setLevel(logging.DEBUG)
    elif args.verbose:
        logger.setLevel(logging.INFO)
    
    # Validaciones iniciales
    if not os.path.exists(args.entrada):
        logger.error(f"Archivo de entrada no encontrado: {args.entrada}")
        sys.exit(1)
    
    for archivo in [args.memoria_yaml, args.memoria_json]:
        if not os.path.exists(archivo):
            logger.warning(f"Archivo oficial no encontrado: {archivo}. Se crear√° uno nuevo.")
            try:
                with open(archivo, 'w') as f:
                    f.write('[]')
                logger.info(f"Archivo vac√≠o creado: {archivo}")
            except Exception as e:
                logger.error(f"Error creando {archivo}: {str(e)}")
                sys.exit(1)
    
    # Ejecutar proceso principal
    exito = sincronizar_memorias(args)
    sys.exit(0 if exito else 1)

if __name__ == "__main__":
    main()