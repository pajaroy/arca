#!/bin/bash
# @arca-file-indexer.sh
# Descripción: Clasificador automático de archivos para el sistema @arca
# Funcionalidades:
# 1. Clasifica archivos por extensión en carpetas específicas
# 2. Genera metadatos clave (hash, fecha, tamaño)
# 3. Elimina duplicados manteniendo un registro completo
# Uso: ./arca-file-indexer.sh (ejecutar desde cualquier ubicación)

# ==============================================================================
# CONFIGURACIÓN BÁSICA
# ==============================================================================
readonly FORMATO_DIR="$HOME/@arca/.source/og/formato"            # Destino para archivos clasificados
readonly OG_DIR="$HOME/@arca/.source/og/archivo"                 # Origen de archivos sin procesar
readonly METADATA_CSV="$HOME/@arca/.source/database/source.csv"  # DB de metadatos
readonly LOG_FILE="$HOME/@arca/.source/scripts/indexer.log"      # Registro de operaciones

# ==============================================================================
# INICIALIZACIÓN DEL SISTEMA
# ==============================================================================
function init_dirs() {
    # Crea la estructura de directorios requerida
    local subdirs=("markdown" "python" "yaml" "csv" "sql" "otros")
    
    echo "[$(date)] Inicializando directorios..." >> "$LOG_FILE"
    mkdir -p "$FORMATO_DIR" "${subdirs[@]/#/$FORMATO_DIR/}"
}

function setup_csv() {
    # Prepara el archivo CSV con headers
    echo "nombre,ruta,hash_blake3,fecha_modificacion,tamano_bytes,tipo" > "$METADATA_CSV"
}

# ==============================================================================
# FUNCIONES PRINCIPALES
# ==============================================================================
function classify_file() {
    # Clasifica un archivo según su extensión
    local file="$1"
    local ext="${file##*.}"
    local dest

    case "$ext" in
        md)       dest="$FORMATO_DIR/markdown" ;;
        py)       dest="$FORMATO_DIR/python" ;;
        yaml|yml) dest="$FORMATO_DIR/yaml" ;;
        csv)      dest="$FORMATO_DIR/csv" ;;
        sql)      dest="$FORMATO_DIR/sql" ;;
        *)        dest="$FORMATO_DIR/otros" ;;
    esac

    echo "$dest"
}

function process_metadata() {
    local file="$1"
    local dest="$2"
    
    # Metadatos básicos (from config.yaml)
    local nombre=$(basename "$file")
    local ruta_relativa="${dest#$HOME/@arca}"
    local tipo="${dest##*/}"
    local tamano=$(stat -c%s "$file")
    local fecha_mod=$(date -r "$file" +"%Y-%m-%dT%H:%M:%S")  # Formato ISO
    local hash_blake3=$(b3sum "$file" | cut -d' ' -f1)

    # Validación según config.yaml
    if [[ " ${config[formatos_especiales][ignorar]} " =~ " ${file##*.} " ]]; then
        echo "[$(date)] Archivo ignorado: $file" >> "$LOG_FILE"
        return
    fi

    # Escribir en CSV
    echo "$ruta_relativa,$nombre,$tipo,$tamano,$fecha_mod,$hash_blake3" >> "$METADATA_CSV"
}

# Cargar configuración YAML al inicio
declare -A config
eval "$(python3 -c "
import yaml, json;
cfg = yaml.safe_load(open('$HOME/@arca/.source/config/config.yaml'));
print('declare -A config=' + json.dumps(cfg))
")"

# ==============================================================================
# EJECUCIÓN PRINCIPAL
# ==============================================================================
main() {
    init_dirs
    setup_csv

    echo "==============================================" >> "$LOG_FILE"
    echo "Iniciando indexación @arca - $(date)" >> "$LOG_FILE"
    echo "==============================================" >> "$LOG_FILE"

    # Procesamiento de archivos
    find "$OG_DIR" -type f | while read -r file; do
        dest=$(classify_file "$file")
        mkdir -p "$dest"
        mv "$file" "$dest/"
        process_metadata "$dest/$(basename "$file")" "$dest"
    done

    # Limpieza de duplicados (modo real, no simulación)
    echo "[$(date)] Buscando duplicados en $FORMATO_DIR..." >> "$LOG_FILE"
    fdupes -rd "$FORMATO_DIR" >> "$LOG_FILE" 2>&1

    echo "[$(date)] Proceso completado. Ver resultados en $METADATA_CSV" >> "$LOG_FILE"
    echo "==============================================" >> "$LOG_FILE"
}

main "$@"

#!/bin/bash
# @arca-file-indexer.sh v2.1
# Dependencias: python3, jq, b3sum, fdupes

# ==============================================================================
# CONFIGURACIÓN
# ==============================================================================
function load_config() {
    local yaml_file="$HOME/@arca/.source/config/config.yaml"
    if [[ ! -f "$yaml_file" ]]; then
        echo "[ERROR] Archivo de configuración no encontrado: $yaml_file" >> "$LOG_FILE"
        exit 1
    fi
    
    # Usamos python para validar y cargar
    config_json=$(python3 -c "
import yaml, json, sys; 
try:
    cfg = yaml.safe_load(open('$yaml_file'))
    print(json.dumps(cfg))
except Exception as e:
    print(f'ERROR: {str(e)}', file=sys.stderr)
    exit(1)
")
    
    if [[ "$config_json" == ERROR* ]]; then
        echo "[ERROR] Configuración YAML inválida: ${config_json:6}" >> "$LOG_FILE"
        exit 1
    fi
    
    # Convertir JSON a variables bash
    declare -gA config
    while IFS="=" read -r key value; do
        config["$key"]="$value"
    done < <(jq -r 'paths(scalars) as $p | "\($p|join("_"))=\(getpath($p))"' <<< "$config_json")
}

# ==============================================================================
# INICIALIZACIÓN
# ==============================================================================
init_dirs() {
    mkdir -p "${config[paths_directorios_formato]}"
    for categoria in "${!config[@]}"; do
        if [[ "$categoria" =~ ^formatos_categorias_ ]]; then
            mkdir -p "${config[paths_directorios_formato]}/${categoria#formatos_categorias_}"
        fi
    done
}

# ==============================================================================
# FUNCIONES PRINCIPALES
# ==============================================================================

function setup_csv() {
    # Generar headers desde config.yaml
    headers=$(IFS=,; echo "${config[metadata_campos_obligatorios[*]}")
    echo "$headers" > "$METADATA_CSV"
}

function classify_file() {
    local file="$1"
    local ext="${file##*.}"
    
    # Buscar en categorías definidas
    for categoria in "${!config[@]}"; do
        if [[ "$categoria" =~ ^formatos_categorias_ ]]; then
            local cat_name="${categoria#formatos_categorias_}"
            if [[ " ${config[$categoria]} " =~ " .$ext " ]]; then
                echo "$FORMATO_DIR/$cat_name"
                return
            fi
        fi
    done
    
    echo "$FORMATO_DIR/otros"
}

process_metadata() {
    local file="$1"
    local dest="$2"
    
    # Validar extensiones ignoradas
    if [[ " ${config[metadata_formatos_especiales_ignorar]} " =~ " .${file##*.} " ]]; then
        return
    fi

    # Generar metadatos
    local -A meta=(
        ["ruta"]="${dest#$HOME/@arca}"
        ["nombre"]="$(basename "$file")"
        ["tipo"]="${dest##*/}"
        ["tamano_bytes"]="$(stat -c%s "$file")"
        ["fecha_mod"]="$(date -r "$file" +"%Y-%m-%dT%H:%M:%S")"
        ["hash_blake3"]="$(b3sum "$file" | cut -d' ' -f1)"
    )

    # Escribir CSV
    local csv_line
    IFS=, read -r -a campos <<< "${config[metadata_campos_obligatorios]}"
    for campo in "${campos[@]}"; do
        csv_line+="${meta[$campo]},"
    done
    echo "${csv_line%,}" >> "$METADATA_CSV"
}

